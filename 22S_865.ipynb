{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMA 2022S 865, Individual Assignment 1\n",
    "\n",
    "Version 2: Updated January 1, 2022.\n",
    "\n",
    "- Gopala Goyal\n",
    "- 20254605\n",
    "- 2\n",
    "- January 8, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - ELI5\n",
    "\n",
    "_“If you can't explain it simply, you don't understand it well enough.” – Albert Einstein_\n",
    "\n",
    "Explaining technical concepts to a non-technical audience is an underappreciated skill; one which the GMMA/MMA program aims to give its students; and one that will truly set you apart in the job market. The only way to gain a skill is by practice, so here we go.\n",
    "\n",
    "Answer each question below as though you were talking to a 5 year old (equivalently: a grandma, or a completely non-technical manager, or an Ivey grad). Use your own words. Use analogies where possible. Examples are better than theory. Keep it short, but be complete. Use simple, plain English. Do not use business buzzwords like _actualize, empower, fungible, leverage, or synergize_. Do not use technical buzzwords that most people don’t know like _model, agile, bandwidth, IoT, blockchain, AR, VR, actionable insights_. Inform the audience without going into too much technical detail. Your goal is to truly help them understand, not to give what you feel is a “technically precise” answer and move on (but they still don’t understand!). Don’t be that guy!\n",
    "\n",
    "Please keep each answer to 1000 characters or less.\n",
    "\n",
    "Finally, feel free to use [Markdown syntax](https://www.markdownguide.org/basic-syntax/) to format your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: What is “Big Data” and how is it different than “regular data”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: What is Hadoop? Hint: What problems in previous data storage and processing was Hadoop designed to solve? How did Hadoop accomplish that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: How does Big Data and the cloud help Machine Learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: What is NoSQL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Name three ways topic modeling could help a bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: What is Apache Spark, exactly, and what are its pros and cons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Sentiment Analysis via the ML-based approach\n",
    "\n",
    "Download the “Product Sentiment” dataset from the course portal: sentiment_train.csv and sentiment_test.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.a. Loading and Prep\n",
    "\n",
    "Load, clean, and preprocess the data as you find necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  600 non-null    object\n",
      " 1   Polarity  600 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0  A good commentary of today's love and undoubte...         1\n",
      "1  For people who are first timers in film making...         1\n",
      "2  It was very popular when I was in the cinema, ...         1\n",
      "3  It's a feel-good film and that's how I felt wh...         1\n",
      "4  It has northern humour and positive about the ...         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# TODO: import other libraries as necessary\n",
    "\n",
    "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "\n",
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_test.info())\n",
    "print(df_test.head())\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.Polarity.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "# Tokenization\n",
    "# Removing Stop Words\n",
    "# Removing punctuation and character\n",
    "# Spelling correction\n",
    "# Lemmatization or Stemming - Standardizing the word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing/wrong values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLengthCol(dataframe,col):\n",
    "    dataframe['review_length']  = dataframe[col].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>DELICIOUS!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Incredible!.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>Disappointed!.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>disappointing.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>WORTHWHILE.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>Excellent!.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>disappointed.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Brilliant!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>10-Oct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>Horrible!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>Awful.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence  Polarity  review_length\n",
       "26            #NAME?         0              1\n",
       "71            #NAME?         1              1\n",
       "165      DELICIOUS!!         1              1\n",
       "219           #NAME?         1              1\n",
       "904           #NAME?         0              1\n",
       "1185    Incredible!.         1              1\n",
       "1463  Disappointed!.         0              1\n",
       "1751  disappointing.         0              1\n",
       "1777     WORTHWHILE.         1              1\n",
       "1877     Excellent!.         1              1\n",
       "1993   disappointed.         0              1\n",
       "2124    Brilliant!           1              1\n",
       "2125          10-Oct         1              1\n",
       "2155     Horrible!           0              1\n",
       "2162        Awful.           0              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createLengthCol(df_train,'Sentence')\n",
    "df_train[df_train.review_length==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We need to remove the rows with data as '#NAME?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train[df_train.Sentence == \"#NAME?\"].index).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>Almost all of the songs in Cover Girl are old-...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>The most annoying thing about 'Cover Girl' is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>Unfortunately, 'Cover Girl' is an example of h...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>Non-linear narration thus many flashbacks and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>The good cinematography also makes her and Mon...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2396 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Polarity  \\\n",
       "0                              Wow... Loved this place.         1   \n",
       "1                                    Crust is not good.         0   \n",
       "2             Not tasty and the texture was just nasty.         0   \n",
       "3     Stopped by during the late May bank holiday of...         1   \n",
       "4     The selection on the menu was great and so wer...         1   \n",
       "...                                                 ...       ...   \n",
       "2391  Almost all of the songs in Cover Girl are old-...         0   \n",
       "2392  The most annoying thing about 'Cover Girl' is ...         0   \n",
       "2393  Unfortunately, 'Cover Girl' is an example of h...         0   \n",
       "2394  Non-linear narration thus many flashbacks and ...         1   \n",
       "2395  The good cinematography also makes her and Mon...         1   \n",
       "\n",
       "      review_length  \n",
       "0                 4  \n",
       "1                 4  \n",
       "2                 8  \n",
       "3                15  \n",
       "4                12  \n",
       "...             ...  \n",
       "2391             14  \n",
       "2392             20  \n",
       "2393             16  \n",
       "2394             12  \n",
       "2395             12  \n",
       "\n",
       "[2396 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to clean data\n",
    "#Remove punctuations\n",
    "#Remove numbers\n",
    "#Lowercase the string\n",
    "#Split the strings on white spaces\n",
    "#Remove Stopwords\n",
    "#Lemmatization\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def text_cleaner(text):\n",
    "    r = text.translate(str.maketrans(\"\",\"\",string.punctuation)) \n",
    "    r = re.sub(r'\\d+', '',r) \n",
    "    r = r.lower()\n",
    "    r = r.split()\n",
    "    r = [word for word in r if word not in stopwords.words('english')]\n",
    "    r = [lemmatizer.lemmatize(word) for word in r]\n",
    "    r = ' '.join(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clean_sentence'] = df_train.Sentence.apply(lambda text:text_cleaner(text))\n",
    "createLengthCol(df_train,'clean_sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Features with Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns  = [\"Polarity\"])\n",
    "y = df_train.Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply TF-IDF on cleaned sentence feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer()\n",
    "X_cv = cv.fit_transform(X.clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,pd.DataFrame(data=X_cv.toarray(), columns = cv.get_feature_names())],axis = 1).drop(columns = ['Sentence','clean_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_length</th>\n",
       "      <th>abhor</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abound</th>\n",
       "      <th>abovepretty</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutel</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youthful</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>za</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombiez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2396 rows × 3629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_length  abhor  ability  able  abound  abovepretty  absolute  \\\n",
       "0                 3    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "1                 2    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "2                 3    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "3                 9    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "4                 4    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "...             ...    ...      ...   ...     ...          ...       ...   \n",
       "2391              6    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "2392              9    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "2393             10    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "2394             10    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "2395              8    0.0      0.0   0.0     0.0          0.0       0.0   \n",
       "\n",
       "      absolutel  absolutely  absolutley  ...  young  youre  youthful  yucky  \\\n",
       "0           0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "1           0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "2           0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "3           0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "4           0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "...         ...         ...         ...  ...    ...    ...       ...    ...   \n",
       "2391        0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "2392        0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "2393        0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "2394        0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "2395        0.0         0.0         0.0  ...    0.0    0.0       0.0    0.0   \n",
       "\n",
       "      yukon  yum  yummy   za  zero  zombiez  \n",
       "0       0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "1       0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "2       0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "3       0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "4       0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "...     ...  ...    ...  ...   ...      ...  \n",
       "2391    0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "2392    0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "2393    0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "2394    0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "2395    0.0  0.0    0.0  0.0   0.0      0.0  \n",
       "\n",
       "[2396 rows x 3629 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A good commentary of today's love and undoubte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For people who are first timers in film making...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was very popular when I was in the cinema, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a feel-good film and that's how I felt wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It has northern humour and positive about the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Polarity\n",
       "0    A good commentary of today's love and undoubte...         1\n",
       "1    For people who are first timers in film making...         1\n",
       "2    It was very popular when I was in the cinema, ...         1\n",
       "3    It's a feel-good film and that's how I felt wh...         1\n",
       "4    It has northern humour and positive about the ...         1\n",
       "..                                                 ...       ...\n",
       "595  I just got bored watching Jessice Lange take h...         0\n",
       "596  Unfortunately, any virtue in this film's produ...         0\n",
       "597                   In a word, it is embarrassing.           0\n",
       "598                               Exceptionally bad!           0\n",
       "599  All in all its an insult to one's intelligence...         0\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "createLengthCol(df_test,'Sentence')\n",
    "df_test[df_test.review_length==1]\n",
    "df_test['clean_sentence'] = df_test.Sentence.apply(lambda text:text_cleaner(text))\n",
    "createLengthCol(df_test,'clean_sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns  = [\"Polarity\"])\n",
    "y_test = df_test.Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cv = cv.transform(X_test.clean_sentence)\n",
    "X_test = pd.concat([X_test,pd.DataFrame(data=X_test_cv.toarray(), columns = cv.get_feature_names())],axis = 1).drop(columns = ['Sentence','clean_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.b. Modeling\n",
    "\n",
    "Use your favorite ML algorithm to train a classification model.  Don’t forget everything that we’ve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[251,  36],\n",
       "       [116, 197]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# confusion matrix\n",
    "metrics.confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.77       287\n",
      "           1       0.85      0.63      0.72       313\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.76      0.75      0.74       600\n",
      "weighted avg       0.77      0.75      0.74       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.c. Assessing\n",
    "\n",
    "Use the testing data to measure the accuracy and F1-score of your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Given the accuracy and F1-score of your model, are you satisfied with the results, from a business point of view? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Show five example instances in which your model’s predictions were incorrect. Describe why you think the model was wrong. Don’t just guess: dig deep to figure out the root cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feel free to use code as well to answer this question. Or not. Up to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
