{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMA 2022S 865, Individual Assignment 1\n",
    "\n",
    "Version 2: Updated January 1, 2022.\n",
    "\n",
    "- Gopala Goyal\n",
    "- 20254605\n",
    "- 2\n",
    "- January 8, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - ELI5\n",
    "\n",
    "_“If you can't explain it simply, you don't understand it well enough.” – Albert Einstein_\n",
    "\n",
    "Explaining technical concepts to a non-technical audience is an underappreciated skill; one which the GMMA/MMA program aims to give its students; and one that will truly set you apart in the job market. The only way to gain a skill is by practice, so here we go.\n",
    "\n",
    "Answer each question below as though you were talking to a 5 year old (equivalently: a grandma, or a completely non-technical manager, or an Ivey grad). Use your own words. Use analogies where possible. Examples are better than theory. Keep it short, but be complete. Use simple, plain English. Do not use business buzzwords like _actualize, empower, fungible, leverage, or synergize_. Do not use technical buzzwords that most people don’t know like _model, agile, bandwidth, IoT, blockchain, AR, VR, actionable insights_. Inform the audience without going into too much technical detail. Your goal is to truly help them understand, not to give what you feel is a “technically precise” answer and move on (but they still don’t understand!). Don’t be that guy!\n",
    "\n",
    "Please keep each answer to 1000 characters or less.\n",
    "\n",
    "Finally, feel free to use [Markdown syntax](https://www.markdownguide.org/basic-syntax/) to format your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: What is “Big Data” and how is it different than “regular data”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Any information that is too large, that cannot fit into one computer or even if it can fit into one computer, but the computer cannot handle the processing of that information alone and needs help from other computers to process it, that large information is known as Big Data. Also, it never stops getting bigger and bigger. The Big data is something that constantly increasing over time. It can be inconsistent and unstructured.\n",
    "\n",
    "- For example, if there are 50 students in a class and we need to gather their progress report, scores, marks etc., it is easy because 50 is a very small number. However, when we need to get the same information for the entire school or even entire city of Toronto, the information will be very large, maybe able to fit into a computers' memory, but it will be large enough to be called as Big Data. As the number of students in Toronto increases, the size of the data will increase every now and then.\n",
    "\n",
    "- Regular data is organised information that is structured, is smaller in size than big data, and can be handled by lesser number of computers.\n",
    "\n",
    "- Regular data is stored and maintained using a big computer however Big data stored on numerous big computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: What is Hadoop? Hint: What problems in previous data storage and processing was Hadoop designed to solve? How did Hadoop accomplish that?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hadoop is a computer program that makes it possible for users to manage huge amounts of data, called Big Data, and helps multiple computers to work together and help in processing Big Data. It can store enormous amounts of data such as pictures, music, text, video or any kind of information you can think of. It stands on 4 pillars:\n",
    "  - HDFS which stores data, Hadoop distributed file system\n",
    "  - YARN - 'Yet another resource negotiator ' which tells which computer will do what processing\n",
    "  - Mapreduce - It distributes and splits the processes and helps computers know what they have to do\n",
    "  - Hadoop Common - It provides resources/utilities for other Hadoop components\n",
    "\n",
    "\n",
    "- Primary advantages of Hadoop\n",
    "  - Because it helps in using multiple computers, if one computer fails, Hadoop makes sure that the processing doesn't stop\n",
    "  - It helps in increasing or decreasing the number of computers as and when required\n",
    "  - It works as and when the data arrives so it helps in real time processing\n",
    "\n",
    "\n",
    "- Problem that Haddop solved in previous data storage and processing\n",
    "  - As compared to the previous data storage and processing systems, Hadoop is cheaper and more effective\n",
    "  - It supports data from many sources\n",
    "  - Hadoop runs on many computers at once so it allows large amount of data to be processed at once and stored in multiple computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: How does Big Data and the cloud help Machine Learning? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Everyday, the computers are getting smarter (not that the people are getting dumber), the one reason behind that is that the computers are learning a lot from the large information that we collect. The big data (as explained in Q1) helps the computers learn about how the world works, how human beings handle day to day tasks. This process of making computers smarter is known as Machine Learning.\n",
    "\n",
    "- Cloud services are the ways to host big data systems for people who want to help in \"Machine learning process\". The can ask for computers and processing systems as and when they require. The cost and space of having so many computers to store Big Data and do Machine Learning is a lot. These issues are addressed by cloud platforms. For example, a pay-per-use model lowers expenses while allowing businesses to increase and decrease up as their data and machine learning needs change. Cloud also makes advanced machine learning technologies available without requiring advanced skills.\n",
    "\n",
    "- Machine learning methods play a critical role in today's world. The growth of the internet and improvements in data collection technology are rapidly increasing the complexity of the machine learning tasks we must solve.\n",
    "\n",
    "- The more data we have, the better it is for Machine Learning. For machine learning algorithms, data serves as a form energy. ML algorithms train themselves on data in the same way that sportsmen train to increase their fitness. Because there is more and more data available for training, big data makes ML algorithms more effective. Big data also aids machine learning in producing more reliable analytics and identifying hidden patterns and trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: What is NoSQL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The type of storage in a computer where the information is not stored in the form of rows and columns are referred to as 'NoSQL,' and 'NoSQL' stands for 'not only SQL\". It stores the data in such a way that is tailored to the way the data is structured. Every item or a document in NoSQL can be of different structure and NoSQL is powerful enough to store the different structure within itself.\n",
    "\n",
    "- It allows for the storage and management of big data that could be non-structured or even semi-structured . They are also built to manage a large volume of data read and write.\n",
    "\n",
    "- Every document in a NoSQL are like human beings, every human being has a similar set of traits such as 2 eyes, 1 nose, 2 hands etc however every person has their own structure, qualities. NoSQL here is like earth which is storing every individual in itself.\n",
    "\n",
    "- NoSQL databases have flexible schemas and they can handle a broad range of data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Name three ways topic modeling could help a bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Insert your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: What is Apache Spark, exactly, and what are its pros and cons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apache Spark is a data processing framework which is used to process lots of information quickly. It has the ability to use multiple computers, their memory, storage etc. to perform the processing. It can use multiple computers either by itself or can take help from other softwares.\n",
    "\n",
    "- Ability to process very large data with speed and efficiency is important for machine learning process as it needs the power of many computers at once and Apache Spark really does an amazing job to achieve this.\n",
    "\n",
    "- It is stands on 2 major pillars, \n",
    "  - Driver - It breaks the code into many parts that can be spread among multiple computers. \n",
    "  - Executors -  It actually does the processing on each computer and perform the tasks assigned to them. \n",
    "\n",
    "- Some of the pros for using Apache Spark are:\n",
    "\n",
    "    - Speed\n",
    "    - Ease of use\n",
    "    - Supports multiple programming languages (Python, Java, Scala etc.)\n",
    "    - Can run on Multiple platforms\n",
    "    - Open source community is strong\n",
    "    - Advanced analytics\n",
    "\n",
    "- Some of the cons are:\n",
    "\n",
    "    - No file management system\n",
    "    - Lesser Algorithms\n",
    "    - Multi-user - cannot handle many users at once\n",
    "    - Optimization process - no automatic code optimization process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Sentiment Analysis via the ML-based approach\n",
    "\n",
    "Download the “Product Sentiment” dataset from the course portal: sentiment_train.csv and sentiment_test.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.a. Loading and Prep\n",
    "\n",
    "Load, clean, and preprocess the data as you find necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, plot_roc_curve\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  600 non-null    object\n",
      " 1   Polarity  600 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0  A good commentary of today's love and undoubte...         1\n",
      "1  For people who are first timers in film making...         1\n",
      "2  It was very popular when I was in the cinema, ...         1\n",
      "3  It's a feel-good film and that's how I felt wh...         1\n",
      "4  It has northern humour and positive about the ...         1\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "\n",
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_test.info())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.Polarity.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing/wrong values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLengthCol(dataframe,col):\n",
    "    dataframe['review_length']  = dataframe[col].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>DELICIOUS!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Incredible!.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>Disappointed!.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>disappointing.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>WORTHWHILE.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>Excellent!.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>disappointed.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Brilliant!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>10-Oct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>Horrible!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>Awful.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence  Polarity  review_length\n",
       "26            #NAME?         0              1\n",
       "71            #NAME?         1              1\n",
       "165      DELICIOUS!!         1              1\n",
       "219           #NAME?         1              1\n",
       "904           #NAME?         0              1\n",
       "1185    Incredible!.         1              1\n",
       "1463  Disappointed!.         0              1\n",
       "1751  disappointing.         0              1\n",
       "1777     WORTHWHILE.         1              1\n",
       "1877     Excellent!.         1              1\n",
       "1993   disappointed.         0              1\n",
       "2124    Brilliant!           1              1\n",
       "2125          10-Oct         1              1\n",
       "2155     Horrible!           0              1\n",
       "2162        Awful.           0              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createLengthCol(df_train,'Sentence')\n",
    "df_train[df_train.review_length==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We need to remove the rows with data as '#NAME?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train[df_train.Sentence == \"#NAME?\"].index).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sentence  Polarity  review_length\n",
       "0  Wow... Loved this place.         1              4\n",
       "1        Crust is not good.         0              4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to clean data\n",
    "#Remove punctuations\n",
    "#Remove numbers\n",
    "#Lowercase the string\n",
    "#Split the strings on white spaces\n",
    "#Remove Stopwords\n",
    "#Lemmatization\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#exclude_words = set((\"not\", \"wasn't\"))\n",
    "#new_stop_words = set(stopwords.words('english')) - exclude_words\n",
    "\n",
    "def text_cleaner(text):\n",
    "    r = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    r = r.translate(str.maketrans(\"\",\"\",string.punctuation)) \n",
    "    r = re.sub(r'\\d+', '',r) \n",
    "    r = r.lower()\n",
    "    r = r.split()\n",
    "    r = [word for word in r if word not in stopwords.words('english')]\n",
    "    r = [lemmatizer.lemmatize(word) for word in r]\n",
    "    r = ' '.join(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clean_sentence'] = df_train.Sentence.apply(lambda text:text_cleaner(text))\n",
    "createLengthCol(df_train,'clean_sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Features with Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns  = [\"Polarity\"])\n",
    "y = df_train.Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Count Vectorizer on cleaned sentence feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_cv = cv.fit_transform(X.clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,pd.DataFrame(data=X_cv.toarray(), columns = cv.get_feature_names())],axis = 1).drop(columns = ['Sentence','clean_sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A good commentary of today's love and undoubte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For people who are first timers in film making...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Polarity\n",
       "0  A good commentary of today's love and undoubte...         1\n",
       "1  For people who are first timers in film making...         1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sentence  Polarity  review_length\n",
      "388   10-Oct         1              1\n"
     ]
    }
   ],
   "source": [
    "createLengthCol(df_test,'Sentence')\n",
    "print(df_test[df_test.review_length==1])\n",
    "df_test['clean_sentence'] = df_test.Sentence.apply(lambda text:text_cleaner(text))\n",
    "createLengthCol(df_test,'clean_sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns  = [\"Polarity\"])\n",
    "y_test = df_test.Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cv = cv.transform(X_test.clean_sentence)\n",
    "X_test = pd.concat([X_test,pd.DataFrame(data=X_test_cv.toarray(), columns = cv.get_feature_names())],axis = 1).drop(columns = ['Sentence','clean_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_length</th>\n",
       "      <th>abhor</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abound</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutel</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutley</th>\n",
       "      <th>abstruse</th>\n",
       "      <th>ac</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>accessable</th>\n",
       "      <th>accessing</th>\n",
       "      <th>accessory</th>\n",
       "      <th>accessoryone</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>accomodate</th>\n",
       "      <th>accompanied</th>\n",
       "      <th>according</th>\n",
       "      <th>accountant</th>\n",
       "      <th>accurately</th>\n",
       "      <th>accused</th>\n",
       "      <th>ache</th>\n",
       "      <th>acknowledged</th>\n",
       "      <th>across</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>activate</th>\n",
       "      <th>activated</th>\n",
       "      <th>activesync</th>\n",
       "      <th>actor</th>\n",
       "      <th>actress</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapter</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>addition</th>\n",
       "      <th>additional</th>\n",
       "      <th>address</th>\n",
       "      <th>adhesive</th>\n",
       "      <th>admiration</th>\n",
       "      <th>adorable</th>\n",
       "      <th>adrift</th>\n",
       "      <th>adventure</th>\n",
       "      <th>advertised</th>\n",
       "      <th>advise</th>\n",
       "      <th>aerial</th>\n",
       "      <th>affected</th>\n",
       "      <th>affleck</th>\n",
       "      <th>affordable</th>\n",
       "      <th>afraid</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>age</th>\n",
       "      <th>aggravating</th>\n",
       "      <th>ago</th>\n",
       "      <th>agreed</th>\n",
       "      <th>ahead</th>\n",
       "      <th>aimless</th>\n",
       "      <th>aired</th>\n",
       "      <th>airline</th>\n",
       "      <th>airport</th>\n",
       "      <th>akin</th>\n",
       "      <th>ala</th>\n",
       "      <th>alarm</th>\n",
       "      <th>albondigas</th>\n",
       "      <th>alexander</th>\n",
       "      <th>allergy</th>\n",
       "      <th>allison</th>\n",
       "      <th>allot</th>\n",
       "      <th>allow</th>\n",
       "      <th>allowing</th>\n",
       "      <th>allows</th>\n",
       "      <th>almond</th>\n",
       "      <th>almost</th>\n",
       "      <th>alone</th>\n",
       "      <th>along</th>\n",
       "      <th>alot</th>\n",
       "      <th>already</th>\n",
       "      <th>also</th>\n",
       "      <th>although</th>\n",
       "      <th>aluminum</th>\n",
       "      <th>always</th>\n",
       "      <th>amateurish</th>\n",
       "      <th>amaze</th>\n",
       "      <th>amazed</th>\n",
       "      <th>amazing</th>\n",
       "      <th>amazon</th>\n",
       "      <th>ambiance</th>\n",
       "      <th>ambience</th>\n",
       "      <th>america</th>\n",
       "      <th>amount</th>\n",
       "      <th>amp</th>\n",
       "      <th>ample</th>\n",
       "      <th>andddd</th>\n",
       "      <th>angeles</th>\n",
       "      <th>angelina</th>\n",
       "      <th>angle</th>\n",
       "      <th>angry</th>\n",
       "      <th>animal</th>\n",
       "      <th>anne</th>\n",
       "      <th>annoying</th>\n",
       "      <th>another</th>\n",
       "      <th>answer</th>\n",
       "      <th>ant</th>\n",
       "      <th>antena</th>\n",
       "      <th>anthony</th>\n",
       "      <th>anti</th>\n",
       "      <th>anticipated</th>\n",
       "      <th>anymore</th>\n",
       "      <th>anyone</th>\n",
       "      <th>anything</th>\n",
       "      <th>anytime</th>\n",
       "      <th>anyway</th>\n",
       "      <th>anyways</th>\n",
       "      <th>anywhere</th>\n",
       "      <th>apart</th>\n",
       "      <th>apartment</th>\n",
       "      <th>apologize</th>\n",
       "      <th>apology</th>\n",
       "      <th>app</th>\n",
       "      <th>appalling</th>\n",
       "      <th>apparently</th>\n",
       "      <th>appealing</th>\n",
       "      <th>appearance</th>\n",
       "      <th>appears</th>\n",
       "      <th>appetite</th>\n",
       "      <th>appetizer</th>\n",
       "      <th>applause</th>\n",
       "      <th>apple</th>\n",
       "      <th>applifies</th>\n",
       "      <th>appointment</th>\n",
       "      <th>approval</th>\n",
       "      <th>apt</th>\n",
       "      <th>area</th>\n",
       "      <th>arepas</th>\n",
       "      <th>arguing</th>\n",
       "      <th>aria</th>\n",
       "      <th>armband</th>\n",
       "      <th>around</th>\n",
       "      <th>array</th>\n",
       "      <th>arrival</th>\n",
       "      <th>arrived</th>\n",
       "      <th>arrives</th>\n",
       "      <th>arriving</th>\n",
       "      <th>art</th>\n",
       "      <th>article</th>\n",
       "      <th>articulated</th>\n",
       "      <th>artiness</th>\n",
       "      <th>artist</th>\n",
       "      <th>artistic</th>\n",
       "      <th>artless</th>\n",
       "      <th>asia</th>\n",
       "      <th>ask</th>\n",
       "      <th>asked</th>\n",
       "      <th>asking</th>\n",
       "      <th>aspect</th>\n",
       "      <th>assistant</th>\n",
       "      <th>assumed</th>\n",
       "      <th>assure</th>\n",
       "      <th>ate</th>\n",
       "      <th>atleast</th>\n",
       "      <th>atmosphere</th>\n",
       "      <th>atrocious</th>\n",
       "      <th>atrocity</th>\n",
       "      <th>att</th>\n",
       "      <th>attached</th>\n",
       "      <th>attack</th>\n",
       "      <th>attacked</th>\n",
       "      <th>attempt</th>\n",
       "      <th>attempting</th>\n",
       "      <th>attention</th>\n",
       "      <th>attentive</th>\n",
       "      <th>attitude</th>\n",
       "      <th>attractive</th>\n",
       "      <th>audience</th>\n",
       "      <th>audio</th>\n",
       "      <th>auju</th>\n",
       "      <th>authentic</th>\n",
       "      <th>author</th>\n",
       "      <th>auto</th>\n",
       "      <th>available</th>\n",
       "      <th>average</th>\n",
       "      <th>avocado</th>\n",
       "      <th>avoid</th>\n",
       "      <th>avoided</th>\n",
       "      <th>avoiding</th>\n",
       "      <th>awarded</th>\n",
       "      <th>away</th>\n",
       "      <th>awesome</th>\n",
       "      <th>awful</th>\n",
       "      <th>awkward</th>\n",
       "      <th>awkwardly</th>\n",
       "      <th>awsome</th>\n",
       "      <th>ayce</th>\n",
       "      <th>aye</th>\n",
       "      <th>az</th>\n",
       "      <th>baba</th>\n",
       "      <th>babie</th>\n",
       "      <th>baby</th>\n",
       "      <th>bachi</th>\n",
       "      <th>back</th>\n",
       "      <th>background</th>\n",
       "      <th>backlight</th>\n",
       "      <th>bacon</th>\n",
       "      <th>bad</th>\n",
       "      <th>badly</th>\n",
       "      <th>bagel</th>\n",
       "      <th>bakery</th>\n",
       "      <th>baklava</th>\n",
       "      <th>balance</th>\n",
       "      <th>ball</th>\n",
       "      <th>ballet</th>\n",
       "      <th>bamboo</th>\n",
       "      <th>banana</th>\n",
       "      <th>bank</th>\n",
       "      <th>bar</th>\n",
       "      <th>bare</th>\n",
       "      <th>barely</th>\n",
       "      <th>bargain</th>\n",
       "      <th>barney</th>\n",
       "      <th>barren</th>\n",
       "      <th>bartender</th>\n",
       "      <th>baseball</th>\n",
       "      <th>based</th>\n",
       "      <th>basement</th>\n",
       "      <th>basic</th>\n",
       "      <th>basically</th>\n",
       "      <th>bat</th>\n",
       "      <th>batch</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>batter</th>\n",
       "      <th>battery</th>\n",
       "      <th>bay</th>\n",
       "      <th>bbq</th>\n",
       "      <th>bean</th>\n",
       "      <th>bear</th>\n",
       "      <th>beat</th>\n",
       "      <th>beateous</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>beautifully</th>\n",
       "      <th>beauty</th>\n",
       "      <th>became</th>\n",
       "      <th>...</th>\n",
       "      <th>uninspired</th>\n",
       "      <th>unintelligible</th>\n",
       "      <th>uninteresting</th>\n",
       "      <th>unique</th>\n",
       "      <th>unit</th>\n",
       "      <th>unknown</th>\n",
       "      <th>unless</th>\n",
       "      <th>unlike</th>\n",
       "      <th>unlockable</th>\n",
       "      <th>unnecessary</th>\n",
       "      <th>unneeded</th>\n",
       "      <th>unpredictable</th>\n",
       "      <th>unprofessional</th>\n",
       "      <th>unreal</th>\n",
       "      <th>unrealistic</th>\n",
       "      <th>unrecommended</th>\n",
       "      <th>unreliable</th>\n",
       "      <th>unremarkable</th>\n",
       "      <th>unsatisfactory</th>\n",
       "      <th>unsatisfying</th>\n",
       "      <th>untoasted</th>\n",
       "      <th>unusable</th>\n",
       "      <th>unwatchable</th>\n",
       "      <th>unwelcome</th>\n",
       "      <th>unwrapped</th>\n",
       "      <th>upbeat</th>\n",
       "      <th>update</th>\n",
       "      <th>upgrade</th>\n",
       "      <th>upgrading</th>\n",
       "      <th>uplifting</th>\n",
       "      <th>upload</th>\n",
       "      <th>uploaded</th>\n",
       "      <th>ups</th>\n",
       "      <th>upstairs</th>\n",
       "      <th>ursula</th>\n",
       "      <th>usable</th>\n",
       "      <th>usage</th>\n",
       "      <th>usb</th>\n",
       "      <th>use</th>\n",
       "      <th>used</th>\n",
       "      <th>useful</th>\n",
       "      <th>usefulness</th>\n",
       "      <th>useless</th>\n",
       "      <th>user</th>\n",
       "      <th>using</th>\n",
       "      <th>usual</th>\n",
       "      <th>usually</th>\n",
       "      <th>utter</th>\n",
       "      <th>utterly</th>\n",
       "      <th>vacant</th>\n",
       "      <th>vain</th>\n",
       "      <th>valentine</th>\n",
       "      <th>valley</th>\n",
       "      <th>value</th>\n",
       "      <th>vanilla</th>\n",
       "      <th>vc</th>\n",
       "      <th>veal</th>\n",
       "      <th>vega</th>\n",
       "      <th>vegan</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>veggie</th>\n",
       "      <th>veggitarian</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>velvet</th>\n",
       "      <th>ventilation</th>\n",
       "      <th>ventura</th>\n",
       "      <th>venture</th>\n",
       "      <th>venturing</th>\n",
       "      <th>venue</th>\n",
       "      <th>verbatim</th>\n",
       "      <th>verge</th>\n",
       "      <th>verizon</th>\n",
       "      <th>versatile</th>\n",
       "      <th>version</th>\n",
       "      <th>veteran</th>\n",
       "      <th>vi</th>\n",
       "      <th>via</th>\n",
       "      <th>vibe</th>\n",
       "      <th>video</th>\n",
       "      <th>viewing</th>\n",
       "      <th>villain</th>\n",
       "      <th>vinaigrette</th>\n",
       "      <th>vinegrette</th>\n",
       "      <th>violinist</th>\n",
       "      <th>virgin</th>\n",
       "      <th>visit</th>\n",
       "      <th>visited</th>\n",
       "      <th>visor</th>\n",
       "      <th>visual</th>\n",
       "      <th>visually</th>\n",
       "      <th>vitally</th>\n",
       "      <th>vivid</th>\n",
       "      <th>vodka</th>\n",
       "      <th>voice</th>\n",
       "      <th>voltage</th>\n",
       "      <th>volume</th>\n",
       "      <th>vomited</th>\n",
       "      <th>voodoo</th>\n",
       "      <th>voted</th>\n",
       "      <th>voyage</th>\n",
       "      <th>vx</th>\n",
       "      <th>waaaaaayyyyyyyyyy</th>\n",
       "      <th>waaay</th>\n",
       "      <th>wagyu</th>\n",
       "      <th>wait</th>\n",
       "      <th>waited</th>\n",
       "      <th>waiter</th>\n",
       "      <th>waiting</th>\n",
       "      <th>waitress</th>\n",
       "      <th>wake</th>\n",
       "      <th>walk</th>\n",
       "      <th>walked</th>\n",
       "      <th>walkman</th>\n",
       "      <th>wall</th>\n",
       "      <th>wallet</th>\n",
       "      <th>want</th>\n",
       "      <th>wanted</th>\n",
       "      <th>war</th>\n",
       "      <th>warm</th>\n",
       "      <th>warmer</th>\n",
       "      <th>warmth</th>\n",
       "      <th>warning</th>\n",
       "      <th>warranty</th>\n",
       "      <th>wash</th>\n",
       "      <th>waste</th>\n",
       "      <th>wasted</th>\n",
       "      <th>wasting</th>\n",
       "      <th>watch</th>\n",
       "      <th>watched</th>\n",
       "      <th>watching</th>\n",
       "      <th>water</th>\n",
       "      <th>watered</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>wave</th>\n",
       "      <th>way</th>\n",
       "      <th>waylaid</th>\n",
       "      <th>wayne</th>\n",
       "      <th>wayyy</th>\n",
       "      <th>weak</th>\n",
       "      <th>weaker</th>\n",
       "      <th>wear</th>\n",
       "      <th>weariness</th>\n",
       "      <th>wearing</th>\n",
       "      <th>web</th>\n",
       "      <th>website</th>\n",
       "      <th>wedding</th>\n",
       "      <th>wedge</th>\n",
       "      <th>week</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weight</th>\n",
       "      <th>weird</th>\n",
       "      <th>welcome</th>\n",
       "      <th>well</th>\n",
       "      <th>went</th>\n",
       "      <th>whatever</th>\n",
       "      <th>whatsoever</th>\n",
       "      <th>whelm</th>\n",
       "      <th>whenever</th>\n",
       "      <th>whether</th>\n",
       "      <th>whine</th>\n",
       "      <th>whiny</th>\n",
       "      <th>whistle</th>\n",
       "      <th>white</th>\n",
       "      <th>whoa</th>\n",
       "      <th>whoever</th>\n",
       "      <th>whole</th>\n",
       "      <th>wholesome</th>\n",
       "      <th>whose</th>\n",
       "      <th>wi</th>\n",
       "      <th>wide</th>\n",
       "      <th>wienerschnitzel</th>\n",
       "      <th>wife</th>\n",
       "      <th>wih</th>\n",
       "      <th>wild</th>\n",
       "      <th>wildly</th>\n",
       "      <th>wily</th>\n",
       "      <th>wind</th>\n",
       "      <th>window</th>\n",
       "      <th>wine</th>\n",
       "      <th>wing</th>\n",
       "      <th>winner</th>\n",
       "      <th>wiping</th>\n",
       "      <th>wire</th>\n",
       "      <th>wired</th>\n",
       "      <th>wirefly</th>\n",
       "      <th>wireless</th>\n",
       "      <th>wise</th>\n",
       "      <th>wish</th>\n",
       "      <th>wit</th>\n",
       "      <th>within</th>\n",
       "      <th>without</th>\n",
       "      <th>witnessed</th>\n",
       "      <th>witticism</th>\n",
       "      <th>witty</th>\n",
       "      <th>woa</th>\n",
       "      <th>wobbly</th>\n",
       "      <th>woman</th>\n",
       "      <th>wonder</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>wonderfully</th>\n",
       "      <th>wont</th>\n",
       "      <th>wonton</th>\n",
       "      <th>wood</th>\n",
       "      <th>wooden</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>worked</th>\n",
       "      <th>worker</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>worn</th>\n",
       "      <th>worry</th>\n",
       "      <th>worse</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>worthless</th>\n",
       "      <th>worthwhile</th>\n",
       "      <th>would</th>\n",
       "      <th>wound</th>\n",
       "      <th>wow</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrapped</th>\n",
       "      <th>writer</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrongly</th>\n",
       "      <th>ya</th>\n",
       "      <th>yama</th>\n",
       "      <th>yawn</th>\n",
       "      <th>yay</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yell</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellowtail</th>\n",
       "      <th>yelpers</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>youthful</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>za</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombiez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_length  abhor  ability  able  abound  absolute  absolutel  \\\n",
       "0              8      0        0     0       0         0          0   \n",
       "1              8      0        0     0       0         0          0   \n",
       "\n",
       "   absolutely  absolutley  abstruse  ac  accept  acceptable  access  \\\n",
       "0           0           0         0   0       0           0       0   \n",
       "1           0           0         0   0       0           0       0   \n",
       "\n",
       "   accessable  accessing  accessory  accessoryone  accident  accidentally  \\\n",
       "0           0          0          0             0         0             0   \n",
       "1           0          0          0             0         0             0   \n",
       "\n",
       "   accommodation  accomodate  accompanied  according  accountant  accurately  \\\n",
       "0              0           0            0          0           0           0   \n",
       "1              0           0            0          0           0           0   \n",
       "\n",
       "   accused  ache  acknowledged  across  acted  acting  action  activate  \\\n",
       "0        0     0             0       0      0       0       0         0   \n",
       "1        0     0             0       0      0       0       0         0   \n",
       "\n",
       "   activated  activesync  actor  actress  actual  actually  ad  adapter  add  \\\n",
       "0          0           0      0        0       0         0   0        0    0   \n",
       "1          0           0      0        0       0         0   0        0    0   \n",
       "\n",
       "   added  addition  additional  address  adhesive  admiration  adorable  \\\n",
       "0      0         0           0        0         0           0         0   \n",
       "1      0         0           0        0         0           0         0   \n",
       "\n",
       "   adrift  adventure  advertised  advise  aerial  affected  affleck  \\\n",
       "0       0          0           0       0       0         0        0   \n",
       "1       0          0           0       0       0         0        0   \n",
       "\n",
       "   affordable  afraid  afternoon  age  aggravating  ago  agreed  ahead  \\\n",
       "0           0       0          0    0            0    0       0      0   \n",
       "1           0       0          0    0            0    0       0      0   \n",
       "\n",
       "   aimless  aired  airline  airport  akin  ala  alarm  albondigas  alexander  \\\n",
       "0        0      0        0        0     0    0      0           0          0   \n",
       "1        0      0        0        0     0    0      0           0          0   \n",
       "\n",
       "   allergy  allison  allot  allow  allowing  allows  almond  almost  alone  \\\n",
       "0        0        0      0      0         0       0       0       0      0   \n",
       "1        0        0      0      0         0       0       0       0      0   \n",
       "\n",
       "   along  alot  already  also  although  aluminum  always  amateurish  amaze  \\\n",
       "0      0     0        0     0         0         0       0           0      0   \n",
       "1      0     0        0     0         0         0       0           0      0   \n",
       "\n",
       "   amazed  amazing  amazon  ambiance  ambience  america  amount  amp  ample  \\\n",
       "0       0        0       0         0         0        0       0    0      0   \n",
       "1       0        0       0         0         0        0       0    0      0   \n",
       "\n",
       "   andddd  angeles  angelina  angle  angry  animal  anne  annoying  another  \\\n",
       "0       0        0         0      0      0       0     0         0        0   \n",
       "1       0        0         0      0      0       0     0         0        0   \n",
       "\n",
       "   answer  ant  antena  anthony  anti  anticipated  anymore  anyone  anything  \\\n",
       "0       0    0       0        0     0            0        0       0         0   \n",
       "1       0    0       0        0     0            0        0       0         0   \n",
       "\n",
       "   anytime  anyway  anyways  anywhere  apart  apartment  apologize  apology  \\\n",
       "0        0       0        0         0      0          0          0        0   \n",
       "1        0       0        0         0      0          0          0        0   \n",
       "\n",
       "   app  appalling  apparently  appealing  appearance  appears  appetite  \\\n",
       "0    0          0           0          0           0        0         0   \n",
       "1    0          0           0          0           0        0         0   \n",
       "\n",
       "   appetizer  applause  apple  applifies  appointment  approval  apt  area  \\\n",
       "0          0         0      0          0            0         0    0     0   \n",
       "1          0         0      0          0            0         0    0     0   \n",
       "\n",
       "   arepas  arguing  aria  armband  around  array  arrival  arrived  arrives  \\\n",
       "0       0        0     0        0       0      0        0        0        0   \n",
       "1       0        0     0        0       0      0        0        0        0   \n",
       "\n",
       "   arriving  art  article  articulated  artiness  artist  artistic  artless  \\\n",
       "0         0    0        0            0         0       0         0        0   \n",
       "1         0    0        0            0         0       0         0        0   \n",
       "\n",
       "   asia  ask  asked  asking  aspect  assistant  assumed  assure  ate  atleast  \\\n",
       "0     0    0      0       0       0          0        0       0    0        0   \n",
       "1     0    0      0       0       0          0        0       0    0        0   \n",
       "\n",
       "   atmosphere  atrocious  atrocity  att  attached  attack  attacked  attempt  \\\n",
       "0           0          0         0    0         0       0         0        0   \n",
       "1           0          0         0    0         0       0         0        0   \n",
       "\n",
       "   attempting  attention  attentive  attitude  attractive  audience  audio  \\\n",
       "0           0          0          0         0           0         0      0   \n",
       "1           0          0          0         0           0         0      0   \n",
       "\n",
       "   auju  authentic  author  auto  available  average  avocado  avoid  avoided  \\\n",
       "0     0          0       0     0          0        0        0      0        0   \n",
       "1     0          0       0     0          0        0        0      0        0   \n",
       "\n",
       "   avoiding  awarded  away  awesome  awful  awkward  awkwardly  awsome  ayce  \\\n",
       "0         0        0     0        0      0        0          0       0     0   \n",
       "1         0        0     0        0      0        0          0       0     0   \n",
       "\n",
       "   aye  az  baba  babie  baby  bachi  back  background  backlight  bacon  bad  \\\n",
       "0    0   0     0      0     0      0     0           0          0      0    0   \n",
       "1    0   0     0      0     0      0     0           0          0      0    0   \n",
       "\n",
       "   badly  bagel  bakery  baklava  balance  ball  ballet  bamboo  banana  bank  \\\n",
       "0      0      0       0        0        0     0       0       0       0     0   \n",
       "1      0      0       0        0        0     0       0       0       0     0   \n",
       "\n",
       "   bar  bare  barely  bargain  barney  barren  bartender  baseball  based  \\\n",
       "0    0     0       0        0       0       0          0         0      0   \n",
       "1    0     0       0        0       0       0          0         0      0   \n",
       "\n",
       "   basement  basic  basically  bat  batch  bathroom  batter  battery  bay  \\\n",
       "0         0      0          0    0      0         0       0        0    0   \n",
       "1         0      0          0    0      0         0       0        0    0   \n",
       "\n",
       "   bbq  bean  bear  beat  beateous  beautiful  beautifully  beauty  became  \\\n",
       "0    0     0     0     0         0          0            0       0       0   \n",
       "1    0     0     0     0         0          0            0       0       0   \n",
       "\n",
       "   ...  uninspired  unintelligible  uninteresting  unique  unit  unknown  \\\n",
       "0  ...           0               0              0       0     0        0   \n",
       "1  ...           0               0              0       0     0        0   \n",
       "\n",
       "   unless  unlike  unlockable  unnecessary  unneeded  unpredictable  \\\n",
       "0       0       0           0            0         0              0   \n",
       "1       0       0           0            0         0              0   \n",
       "\n",
       "   unprofessional  unreal  unrealistic  unrecommended  unreliable  \\\n",
       "0               0       0            0              0           0   \n",
       "1               0       0            0              0           0   \n",
       "\n",
       "   unremarkable  unsatisfactory  unsatisfying  untoasted  unusable  \\\n",
       "0             0               0             0          0         0   \n",
       "1             0               0             0          0         0   \n",
       "\n",
       "   unwatchable  unwelcome  unwrapped  upbeat  update  upgrade  upgrading  \\\n",
       "0            0          0          0       0       0        0          0   \n",
       "1            0          0          0       0       0        0          0   \n",
       "\n",
       "   uplifting  upload  uploaded  ups  upstairs  ursula  usable  usage  usb  \\\n",
       "0          0       0         0    0         0       0       0      0    0   \n",
       "1          0       0         0    0         0       0       0      0    0   \n",
       "\n",
       "   use  used  useful  usefulness  useless  user  using  usual  usually  utter  \\\n",
       "0    0     0       0           0        0     0      0      0        0      0   \n",
       "1    0     0       0           0        0     0      0      0        0      0   \n",
       "\n",
       "   utterly  vacant  vain  valentine  valley  value  vanilla  vc  veal  vega  \\\n",
       "0        0       0     0          0       0      0        0   0     0     0   \n",
       "1        0       0     0          0       0      0        0   0     0     0   \n",
       "\n",
       "   vegan  vegetable  vegetarian  veggie  veggitarian  vehicle  velvet  \\\n",
       "0      0          0           0       0            0        0       0   \n",
       "1      0          0           0       0            0        0       0   \n",
       "\n",
       "   ventilation  ventura  venture  venturing  venue  verbatim  verge  verizon  \\\n",
       "0            0        0        0          0      0         0      0        0   \n",
       "1            0        0        0          0      0         0      0        0   \n",
       "\n",
       "   versatile  version  veteran  vi  via  vibe  video  viewing  villain  \\\n",
       "0          0        0        0   0    0     0      0        0        0   \n",
       "1          0        0        0   0    0     0      0        0        0   \n",
       "\n",
       "   vinaigrette  vinegrette  violinist  virgin  visit  visited  visor  visual  \\\n",
       "0            0           0          0       0      0        0      0       0   \n",
       "1            0           0          0       0      0        0      0       0   \n",
       "\n",
       "   visually  vitally  vivid  vodka  voice  voltage  volume  vomited  voodoo  \\\n",
       "0         0        0      0      0      0        0       0        0       0   \n",
       "1         0        0      0      0      0        0       0        0       0   \n",
       "\n",
       "   voted  voyage  vx  waaaaaayyyyyyyyyy  waaay  wagyu  wait  waited  waiter  \\\n",
       "0      0       0   0                  0      0      0     0       0       0   \n",
       "1      0       0   0                  0      0      0     0       0       0   \n",
       "\n",
       "   waiting  waitress  wake  walk  walked  walkman  wall  wallet  want  wanted  \\\n",
       "0        0         0     0     0       0        0     0       0     0       0   \n",
       "1        0         0     0     0       0        0     0       0     0       0   \n",
       "\n",
       "   war  warm  warmer  warmth  warning  warranty  wash  waste  wasted  wasting  \\\n",
       "0    0     0       0       0        0         0     0      0       0        0   \n",
       "1    0     0       0       0        0         0     0      0       0        0   \n",
       "\n",
       "   watch  watched  watching  water  watered  waterproof  wave  way  waylaid  \\\n",
       "0      0        0         0      0        0           0     0    0        0   \n",
       "1      0        0         0      0        0           0     0    0        0   \n",
       "\n",
       "   wayne  wayyy  weak  weaker  wear  weariness  wearing  web  website  \\\n",
       "0      0      0     0       0     0          0        0    0        0   \n",
       "1      0      0     0       0     0          0        0    0        0   \n",
       "\n",
       "   wedding  wedge  week  weekend  weekly  weight  weird  welcome  well  went  \\\n",
       "0        0      0     0        0       0       0      0        0     0     0   \n",
       "1        0      0     0        0       0       0      0        0     0     0   \n",
       "\n",
       "   whatever  whatsoever  whelm  whenever  whether  whine  whiny  whistle  \\\n",
       "0         0           0      0         0        0      0      0        0   \n",
       "1         0           0      0         0        0      0      0        0   \n",
       "\n",
       "   white  whoa  whoever  whole  wholesome  whose  wi  wide  wienerschnitzel  \\\n",
       "0      0     0        0      0          0      0   0     0                0   \n",
       "1      0     0        0      0          0      0   0     0                0   \n",
       "\n",
       "   wife  wih  wild  wildly  wily  wind  window  wine  wing  winner  wiping  \\\n",
       "0     0    0     0       0     0     0       0     0     0       0       0   \n",
       "1     0    0     0       0     0     0       0     0     0       0       0   \n",
       "\n",
       "   wire  wired  wirefly  wireless  wise  wish  wit  within  without  \\\n",
       "0     0      0        0         0     0     0    0       0        0   \n",
       "1     0      0        0         0     0     0    0       0        0   \n",
       "\n",
       "   witnessed  witticism  witty  woa  wobbly  woman  wonder  wonderful  \\\n",
       "0          0          0      0    0       0      0       0          0   \n",
       "1          0          0      0    0       0      0       0          0   \n",
       "\n",
       "   wonderfully  wont  wonton  wood  wooden  word  work  worked  worker  \\\n",
       "0            0     0       0     0       0     0     0       0       0   \n",
       "1            0     0       0     0       0     0     0       0       0   \n",
       "\n",
       "   working  world  worn  worry  worse  worst  worth  worthless  worthwhile  \\\n",
       "0        0      0     0      0      0      0      1          0           0   \n",
       "1        0      0     0      0      0      0      0          0           0   \n",
       "\n",
       "   would  wound  wow  wrap  wrapped  writer  writing  written  wrong  wrongly  \\\n",
       "0      0      0    0     0        0       0        0        0      0        0   \n",
       "1      0      0    0     0        0       0        0        0      0        0   \n",
       "\n",
       "   ya  yama  yawn  yay  yeah  year  yell  yellow  yellowtail  yelpers  yes  \\\n",
       "0   0     0     0    0     0     0     0       0           0        0    0   \n",
       "1   0     0     0    0     0     0     0       0           0        0    0   \n",
       "\n",
       "   yet  young  youthful  yucky  yukon  yum  yummy  za  zero  zombiez  \n",
       "0    0      0         0      0      0    0      0   0     0        0  \n",
       "1    0      0         0      0      0    0      0   0     0        0  \n",
       "\n",
       "[2 rows x 3499 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.b. Modeling\n",
    "\n",
    "Use your favorite ML algorithm to train a classification model.  Don’t forget everything that we’ve learned in our ML course: hyperparameter tuning, cross validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing classifier that you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression base model with 10 fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_micro': 'recall_macro',\n",
    "           'f1_macr':'f1_macro',\n",
    "           'roc_auc':'roc_auc'}\n",
    "scores = pd.DataFrame(cross_validate(lr, X=X, y=y,scoring=scoring, cv=10, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    0.736709\n",
       "8    0.740556\n",
       "0    0.749844\n",
       "6    0.772910\n",
       "3    0.787467\n",
       "1    0.789562\n",
       "4    0.820756\n",
       "2    0.829021\n",
       "5    0.829021\n",
       "7    0.840532\n",
       "Name: test_f1_macr, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.test_f1_macr.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Hyperparameter Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7896377815616248\n",
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "param_dict = {\n",
    "'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "'C' : [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]    \n",
    "}\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(lr, param_dict, scoring='f1_macro', n_jobs=-1, cv=10)\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_prec_macro</th>\n",
       "      <th>test_rec_micro</th>\n",
       "      <th>test_f1_macr</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.002933</td>\n",
       "      <td>0.234546</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750261</td>\n",
       "      <td>0.749844</td>\n",
       "      <td>0.749844</td>\n",
       "      <td>0.863115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.129336</td>\n",
       "      <td>0.194638</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.801961</td>\n",
       "      <td>0.790888</td>\n",
       "      <td>0.789562</td>\n",
       "      <td>0.878742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.164299</td>\n",
       "      <td>0.101215</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.829783</td>\n",
       "      <td>0.828981</td>\n",
       "      <td>0.829021</td>\n",
       "      <td>0.902702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.006222</td>\n",
       "      <td>0.180904</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.787959</td>\n",
       "      <td>0.787659</td>\n",
       "      <td>0.787467</td>\n",
       "      <td>0.872422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.962207</td>\n",
       "      <td>0.500168</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.821846</td>\n",
       "      <td>0.821064</td>\n",
       "      <td>0.820756</td>\n",
       "      <td>0.915966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.638282</td>\n",
       "      <td>0.332116</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.829391</td>\n",
       "      <td>0.828911</td>\n",
       "      <td>0.829021</td>\n",
       "      <td>0.907335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.098304</td>\n",
       "      <td>0.453930</td>\n",
       "      <td>0.774059</td>\n",
       "      <td>0.777920</td>\n",
       "      <td>0.773288</td>\n",
       "      <td>0.772910</td>\n",
       "      <td>0.864407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.388251</td>\n",
       "      <td>0.173712</td>\n",
       "      <td>0.841004</td>\n",
       "      <td>0.843582</td>\n",
       "      <td>0.840454</td>\n",
       "      <td>0.840532</td>\n",
       "      <td>0.885278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.639910</td>\n",
       "      <td>0.202006</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>0.780618</td>\n",
       "      <td>0.746813</td>\n",
       "      <td>0.740556</td>\n",
       "      <td>0.810618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.558139</td>\n",
       "      <td>0.098074</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.752514</td>\n",
       "      <td>0.739179</td>\n",
       "      <td>0.736709</td>\n",
       "      <td>0.797276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_acc  test_prec_macro  test_rec_micro  \\\n",
       "0  6.002933    0.234546  0.750000         0.750261        0.749844   \n",
       "1  6.129336    0.194638  0.791667         0.801961        0.790888   \n",
       "2  6.164299    0.101215  0.829167         0.829783        0.828981   \n",
       "3  6.006222    0.180904  0.787500         0.787959        0.787659   \n",
       "4  5.962207    0.500168  0.820833         0.821846        0.821064   \n",
       "5  5.638282    0.332116  0.829167         0.829391        0.828911   \n",
       "6  6.098304    0.453930  0.774059         0.777920        0.773288   \n",
       "7  6.388251    0.173712  0.841004         0.843582        0.840454   \n",
       "8  3.639910    0.202006  0.748954         0.780618        0.746813   \n",
       "9  3.558139    0.098074  0.740586         0.752514        0.739179   \n",
       "\n",
       "   test_f1_macr  test_roc_auc  \n",
       "0      0.749844      0.863115  \n",
       "1      0.789562      0.878742  \n",
       "2      0.829021      0.902702  \n",
       "3      0.787467      0.872422  \n",
       "4      0.820756      0.915966  \n",
       "5      0.829021      0.907335  \n",
       "6      0.772910      0.864407  \n",
       "7      0.840532      0.885278  \n",
       "8      0.740556      0.810618  \n",
       "9      0.736709      0.797276  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tuned = LogisticRegression(C=1, penalty='l2',solver='newton-cg')\n",
    "scores_tuned = pd.DataFrame(cross_validate(lr_tuned, X=X, y=y,scoring=scoring, cv=10, n_jobs=-1))\n",
    "scores_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, solver='newton-cg')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_tuned.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.c. Assessing\n",
    "\n",
    "Use the testing data to measure the accuracy and F1-score of your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254,  33],\n",
       "       [112, 201]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254,  33],\n",
       "       [112, 201]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78       287\n",
      "           1       0.86      0.64      0.73       313\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.78      0.76      0.76       600\n",
      "weighted avg       0.78      0.76      0.76       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x13238b990>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAliklEQVR4nO3de3xU9bnv8c9jwEIRERD24SImItoGuajRqIAgbSmoLaJWBOvtYC27ola3PeCl4qVb7JFXpWytFJGqraBsFUWqSN0HxSs3iVyiQBTEIFYE5SJFiTznjzUTh2SSrJCsSWbm+3695pVZs36z5lkJrGd+l/X7mbsjIiLZ66CGDkBERBqWEoGISJZTIhARyXJKBCIiWU6JQEQkyzVp6ABq6/DDD/fc3NyGDkNEJK0sW7bsM3dvl2xf2iWC3Nxcli5d2tBhiIikFTP7sKp9ahoSEclySgQiIllOiUBEJMspEYiIZDklAhGRLBdZIjCz6Wb2qZmtqmK/mdlkMysxsxVmdkJUsYiISNWirBE8DAyuZv8QoFvscSXwQISxiIhIFSK7j8DdF5pZbjVFhgKPejAP9ltmdpiZdXD3zVHFJCJSWzMWbeTZok0NHQYA+R0PZfxPutf7cRuyj6AT8FHCdmnstUrM7EozW2pmS7ds2ZKS4EREAJ4t2kTx5h0NHUakGvLOYkvyWtJVctx9KjAVoKCgQCvpiEhodf1GX7x5B/kdDuWJX55aj1E1Lg2ZCEqBIxK2OwMfN1AsItLI1FeTzKL12wAozGtzQO/P73AoQ3snbazIGA2ZCOYAY8zscaAQ2K7+AZH0Vp/t6XW9gMcV5rVhaO9OjCzsUh9hZaTIEoGZzQQGAIebWSkwHmgK4O5TgOeBM4ESYDdweVSxiEj9S3bRr6+Ld/wYuoCnRpSjhkbUsN+Bq6L6fBGpu+q+4Se76OvinZ7SbhpqEUmd+IiZ/A6HVtqni37mUCIQyUJh2/KzYcSMKBGIZIWKF/6wbfnZMGJGlAhEMlo8AVS88KtZRxIpEYg0ElFMZZCYAHThl6ooEYg0kANtrqkNJQAJQ4lAJAJhvt2ruUYaCyUCkTo60BurdOGXxkKJQKSOko2110Ve0okSgcgBSKwFaKy9pDslApFaSDYcU2PtJd0pEYiEkCwBqOlHMoUSgQg1j/JRApBMpkQgWaO2M2kmUgKQTKZEIFlDM2mKJKdEIGlDa8+KROOghg5AJKz4N/oDpdE9IsmpRiBpYcaijSxav43CvDb6Ri9Sz1QjkEZvxqKN3DR7JYC+0YtEQIlAGrXEJHDXsB7qzBWJgBKBNGrxzmElAZHoqI9AGlx1o4GKN++gMK+NkoBIhJQIJOVqsyCLRvqIRE+JQFIqsc1fC7KINA5KBFKvws7ZozZ/kcZDiUBqTXP2iGQWJQIJJfHiX93FXhd6kfSjRCDVSjYPvy72IplFiUCqFZ/fRxd/kcylRCBJxWsCmrFTJPPpzmJJKjEJaBy/SGaLNBGY2WAzW2NmJWY2Lsn+Vmb2nJm9Y2arzezyKOORcOIzfcZrAmoOEslskTUNmVkOcD/wI6AUWGJmc9y9OKHYVUCxu//EzNoBa8zsMXf/Oqq4JBBmCKhqAiLZIcoawclAibt/ELuwPw4MrVDGgZZmZsAhwDagLMKYJKa6RV4K89rohi+RLBJlZ3En4KOE7VKgsEKZ+4A5wMdAS2C4u++reCAzuxK4EqBLF12c6kKdwCJSUZQ1AkvymlfY/jFQBHQEegP3mVmllcXdfaq7F7h7Qbt27eo7zqyiTmARqSjKGkEpcETCdmeCb/6JLgfudncHSsxsPfA9YHGEcWU91QREJFGUiWAJ0M3M8oBNwIXAyAplNgI/AF41s38DjgU+iDCmrJTYMRyvDYiIxEXWNOTuZcAY4EXgXWCWu682s9FmNjpW7E7gNDNbCfwPMNbdP4sqpmyV2DGsJiERqSjSO4vd/Xng+QqvTUl4/jEwKMoYslHFoaHqGBaR6ujO4gxUcWioagEiUh3NNZRh4ncFF+a1UQ1AREJRjSDDxJuEVAMQkbCUCDJQYV4b3RUsIqGpaSiNJZsvSMNDRaS2VCNIUzMWbeSm2SvLJ4iLU8ewiNSWagRpKl4T0ORwIlJXqhGkocSRQUoCIlJXSgRpSCODRKQ+KRGkGdUGRKS+hU4EZtYiykAkHNUGRKS+1ZgIzOw0MysmmDgOM+tlZn+KPDKpRLUBEYlCmBrBvQQLyGwFcPd3gNOjDEqSU21ARKIQqmnI3T+q8NI3EcQi1VBtQESiEuY+go/M7DTAzexg4BpizUSSOqoNiEhUwiSC0cAfCRajLwXmA7+KMij5VuJi86oNiEgUwiSCY939osQXzKwP8Ho0IUkiLTYvIlELkwj+CzghxGsSEa0uJiJRqjIRmNmpwGlAOzO7PmHXoUBO1IGJiEhqVDdq6GDgEIJk0TLhsQM4P/rQJD5SSEQkSlXWCNz9FeAVM3vY3T9MYUwSo5FCIpIKYfoIdpvZPUB3oFn8RXcfGFlUovsGRCRlwiSCx4AngLMJhpJeCmyJMqhskmyVMaC8SUi1ARGJWphE0NbdHzKzaxOai16JOrBMlnjxj1/wC/Pa7FemMK8NQ3t3Um1ARCIXJhHsjf3cbGZnAR8DnaMLKfMl3hugC76INLQwieB3ZtYK+A+C+wcOBX4dZVCZLLHtX/cGiEhjUGMicPe5safbgTOg/M5iOQAaCSQijU11N5TlABcQzDE0z91XmdnZwE1Ac+D41ISYOTQSSEQao+pqBA8BRwCLgclm9iFwKjDO3Z9JQWwZZcaijdw0eyWg2oCINC7VJYICoKe77zOzZsBnwNHu/klqQsss8Sahu4b1UG1ARBqV6qaY+Nrd9wG4+x5gbW2TgJkNNrM1ZlZiZuOqKDPAzIrMbHWmD0tVk5CINEbV1Qi+Z2YrYs8N6BrbNsDdvWd1B471MdwP/IhgHYMlZjbH3YsTyhwG/AkY7O4bzaz9gZ+KiIgciOoSwffreOyTgRJ3/wDAzB4HhgLFCWVGAk+7+0YAd/+0jp/ZKCV2EouINDbVTTpX14nmOgGJax2XAoUVyhwDNDWzlwlmNv2juz9a8UBmdiVwJUCXLunVtKJOYhFp7EItXn+ALMlrXmG7CXAicBbwY+C3ZnZMpTe5T3X3AncvaNeuXf1HGiF1EotIYxfmzuIDVUow/DSuM8H0FBXLfObuXwJfmtlCoBewNsK4Ukb3DYhIOgiVCMysOdDF3dfU4thLgG5mlgdsAi4k6BNI9Cxwn5k1IVgIpxC4txaf0ahUnElUM4iKSDqosWnIzH4CFAHzYtu9zWxOTe9z9zJgDPAi8C4wy91Xm9loMxsdK/Nu7LgrCG5cm+buqw7wXBpcfDK5uMK8NmoSEpFGL0yN4DaCEUAvA7h7kZnlhjm4uz8PPF/htSkVtu8B7glzvMZMk8mJSLoK01lc5u7bI48kjWlkkIikszA1glVmNhLIMbNuwDXAG9GG1fglW1xGzUAiko7C1AiuJliv+CtgBsF01L+OMKa0kNgfoL4AEUlnYWoEx7r7zcDNUQeTbvI7HKr+ABFJe2FqBH8ws/fM7E4z6x55RCIiklI1JgJ3PwMYAGwBpprZSjO7JerAREQkNULdUBabfnqymS0A/g9wK/C7KANrjBI7iOOLz4uIpLswN5R938xuM7NVwH0EI4Y6Rx5ZI5TYQZzf4VANFRWRjBCmRvAXYCYwyN0rzhWUddRBLCKZpsZE4O6npCIQERFpGFUmAjOb5e4XmNlK9p8+OtQKZSIikh6qqxFcG/t5dioCaey0ypiIZKoqO4vdfXPs6a/c/cPEB/Cr1ITXeMRHC6mDWEQyTZgbyn6U5LUh9R1IOtACMyKSiarrI/h3gm/+R5nZioRdLYHXow5MRERSo7o+ghnAC8AEYFzC6zvdfVukUTUy6h8QkUxWXSJwd99gZldV3GFmbbIpGah/QEQyWU01grOBZQTDRy1hnwNHRRhXo6P+ARHJVFUmAnc/O/YzL3XhiIhIqoWZa6iPmbWIPf+5mf3BzPTVWEQkQ4QZPvoAsNvMehHMPPoh8NdIoxIRkZQJu3i9A0OBP7r7HwmGkIqISAYIM/voTjO7EbgY6GdmOUDTaMMSEZFUCVMjGE6wcP3/ji1Q0wm4J9KoREQkZcIsVfkJ8BjQyszOBva4+6ORRyYiIikRZtTQBcBi4GfABcAiMzs/6sAai/hdxSIimSpMH8HNwEnu/imAmbUDXgKejDKwxkJ3FYtIpgvTR3BQPAnEbA35vrSXOMeQ7ioWkUwVpkYwz8xeJFi3GILO4+ejC6nxUG1ARLJBmDWLf2Nm5wJ9CeYbmurusyOPrJFQbUBEMl116xF0AyYCXYGVwA3uvilVgYmISGpU19Y/HZgLnEcwA+l/1fbgZjbYzNaYWYmZjaum3Elm9k02jUYSEWksqksELd39QXdf4+4TgdzaHDh2B/L9BMta5gMjzCy/inK/B16szfGjpmGjIpItqusjaGZmx/PtOgTNE7fd/e0ajn0yUOLuHwCY2eME8xUVVyh3NfAUcFItY4/MjEUbuWn2SkAdxSKS+apLBJuBPyRsf5Kw7cDAGo7dCfgoYbsUKEwsYGadgGGxY1WZCMzsSuBKgC5douu4nbFoI88WbSqvCdw1rIc6ikUk41W3MM0ZdTy2JXnNK2xPAsa6+zdmyYqXxzIVmApQUFBQ8Rj15tmiTRRv3kFhXhuG9u6kJCAiWSHMfQQHqhQ4ImG7M/BxhTIFwOOxJHA4cKaZlbn7MxHGVa38DofyxC9PbaiPFxFJuSgTwRKgm5nlAZuAC4GRiQUSl8E0s4eBuQ2ZBEREslFkicDdy8xsDMFooBxguruvNrPRsf1TovpsEREJr8ZEYEG7zUXAUe5+R2y94v/l7otreq+7P0+F6SiqSgDuflmoiEVEpF6FmTzuT8CpwIjY9k6C+wMyiu4bEJFsFaZpqNDdTzCz5QDu/rmZHRxxXCmnCeZEJFuFqRHsjd3961C+HsG+SKNKMU03LSLZLEwimAzMBtqb2X8CrwF3RRpViqk2ICLZLMw01I+Z2TLgBwQ3iZ3j7u9GHlmKqDYgItkuzKihLsBu4LnE19x9Y5SBpYpqAyKS7cJ0Fv+doH/AgGZAHrAG6B5hXCml2oCIZLMwTUM9ErfN7ATgl5FFJCIiKVXrRehj0083mimjRUSkbsL0EVyfsHkQcAKwJbKIREQkpcL0EbRMeF5G0GfwVDThiIhIqlWbCGI3kh3i7r9JUTwiIpJiVfYRmFkTd/+GoClIREQyVHU1gsUESaDIzOYA/w18Gd/p7k9HHJuIiKRAmD6CNsBWgnWF4/cTOKBEICKSAapLBO1jI4ZW8W0CiIts3WAREUmt6u4jyAEOiT1aJjyPP9Ke1iAQEam+RrDZ3e9IWSQNQPMMiYhUXyOwavZlDM0zJCLZrrpE8IOURSEiIg2mykTg7mo8FxHJArWedE5ERDKLEoGISJZTIhARyXJKBCIiWU6JQEQkyykRiIhkOSUCEZEsp0QgIpLllAhERLJcpInAzAab2RozKzGzcUn2X2RmK2KPN8ysV5TxiIhIZZElgth6x/cDQ4B8YISZ5Vcoth7o7+49gTuBqVHFIyIiyUVZIzgZKHH3D9z9a+BxYGhiAXd/w90/j22+BXSOMB4REUkiykTQCfgoYbs09lpVRgEvJNthZlea2VIzW7ply5Z6DFFERKJMBMnWM0i6xKWZnUGQCMYm2+/uU929wN0L2rVrV48hiohImMXrD1QpcETCdmfg44qFzKwnMA0Y4u5bI4xHRESSiLJGsAToZmZ5ZnYwcCEwJ7GAmXUBngYudve1EcYiIiJViKxG4O5lZjYGeBHIAaa7+2ozGx3bPwW4FWgL/MnMAMrcvSCqmEREpLIom4Zw9+eB5yu8NiXh+RXAFVHGICIi1dOdxSIiWU6JQEQkyykRiIhkuaxNBDMWbWTR+m0NHYaISIPL2kTwbNEmAIb2ru5mZxGRzJe1iQCgMK8NIwu7NHQYIiINKisTgZqFRES+lZWJQM1CIiLfyspEAGoWEhGJy9pEICIigUinmGhsZizayLNFmyjevIP8Doc2dDgiIo1CVtUIEpOA+gdERAJZVSMAyO9wKE/88tSGDkNEpNHIqhqBiIhUpkQgIpLllAhERLKcEoGISJZTIhARyXJKBCIiWU6JQEQkyykRiIhkuay7oUwyy969eyktLWXPnj0NHYpIo9CsWTM6d+5M06ZNQ78naxJBfA2Cwrw2DR2K1KPS0lJatmxJbm4uZtbQ4Yg0KHdn69atlJaWkpeXF/p9WdM0pDUIMtOePXto27atkoAIYGa0bdu21jXkrEkEoDUIMpWSgMi3DuT/Q1YlAhERqUyJQKSODjnkkDofY+nSpVxzzTVV7t+wYQMzZswIXR4gNzeXHj160LNnT/r378+HH35Y5zjry5QpU3j00Ufr5VibN2/m7LPP3u+1a6+9lk6dOrFv377y12677TYmTpy4X7nc3Fw+++wzAD755BMuvPBCunbtSn5+PmeeeSZr166tU2xfffUVw4cP5+ijj6awsJANGzYkLTdz5szyv9XgwYPLYwKYNWsW+fn5dO/enZEjRwKwZcsWBg8eXKfYEikRiDQCBQUFTJ48ucr9FRNBTeXjFixYwIoVKxgwYAC/+93v6hynu+93cT1Qo0eP5pJLLqnzcQD+8Ic/8Itf/KJ8e9++fcyePZsjjjiChQsXhjqGuzNs2DAGDBjA+++/T3FxMXfddRf//Oc/6xTbQw89ROvWrSkpKeG6665j7NixlcqUlZVx7bXXlv+tevbsyX333QfAunXrmDBhAq+//jqrV69m0qRJALRr144OHTrw+uuv1ym+uKwZNSSZ7/bnVlP88Y56PWZ+x0MZ/5PutX5fUVERo0ePZvfu3XTt2pXp06fTunVrlixZwqhRo2jRogV9+/blhRdeYNWqVbz88stMnDiRuXPn8sorr3DttdcCQXvvwoULGTduHO+++y69e/fm0ksv5fjjjy8vv2vXLq6++mqWLl2KmTF+/HjOO++8/eI59dRTyxPHli1bGD16NBs3bgRg0qRJ9OnThy1btjBy5Ei2bt3KSSedxLx581i2bBm7du1iyJAhnHHGGbz55ps888wzzJo1i1mzZvHVV18xbNgwbr/9dr788ksuuOACSktL+eabb/jtb3/L8OHDGTduHHPmzKFJkyYMGjSIiRMnctttt3HIIYdwww03VPm7GjBgAIWFhSxYsIAvvviChx56iH79+lX6XT/11FP7JbkFCxZw3HHHMXz4cGbOnMmAAQNq/HstWLCApk2bMnr06PLXevfuXds/eyXPPvsst912GwDnn38+Y8aMwd33a8d3d9ydL7/8krZt27Jjxw6OPvpoAB588EGuuuoqWrduDUD79u3L33fOOefw2GOP0adPnzrHqRqBSAQuueQSfv/737NixQp69OjB7bffDsDll1/OlClTePPNN8nJyUn63okTJ3L//fdTVFTEq6++SvPmzbn77rvp168fRUVFXHfddfuVv/POO2nVqhUrV65kxYoVDBw4sNIx582bxznnnAMEzSbXXXcdS5Ys4amnnuKKK64A4Pbbb2fgwIG8/fbbDBs2rDxRAKxZs4ZLLrmE5cuXs2bNGtatW8fixYspKipi2bJlLFy4kHnz5tGxY0feeecdVq1axeDBg9m2bRuzZ89m9erVrFixgltuuSX07wqCb8uLFy9m0qRJ+70et379elq3bs13vvOd8tdmzpzJiBEjGDZsGHPnzmXv3r1V/ZnKrVq1ihNPPLHGcgD9+vWjd+/elR4vvfRSpbKbNm3iiCOOAKBJkya0atWKrVu37lemadOmPPDAA/To0YOOHTtSXFzMqFGjAFi7di1r166lT58+nHLKKcybN6/8fQUFBbz66quhYq6JagSSMQ7km3sUtm/fzhdffEH//v0BuPTSS/nZz37GF198wc6dOznttNMAGDlyJHPnzq30/j59+nD99ddz0UUXce6559K5c+dqP++ll17i8ccfL9+Of3sEOOOMM/jnP/9J+/bty781v/TSSxQXF5eX2bFjBzt37uS1115j9uzZAAwePHi/4xx55JGccsopAMyfP5/58+dz/PHHA7Br1y7WrVtHv379uOGGGxg7dixnn302/fr1o6ysjGbNmnHFFVdw1llnVWrLr+p3FXfuuecCcOKJJyZtX9+8eTPt2rUr3/766695/vnnuffee2nZsiWFhYXMnz+fs846q8rRNLUdZVObi6+71/h5e/fu5YEHHmD58uUcddRRXH311UyYMIFbbrmFsrIy1q1bx8svv0xpaSn9+vVj1apVHHbYYbRv356PP/64VrFXJdIagZkNNrM1ZlZiZuOS7Dczmxzbv8LMTogyHpGGlOyikMy4ceOYNm0a//rXvzjllFN47733ajxuVRezBQsW8OGHH9K9e3duvfVWIGhDf/PNNykqKqKoqIhNmzbRsmXLauNr0aLFfp934403lr+/pKSEUaNGccwxx7Bs2TJ69OjBjTfeyB133EGTJk1YvHgx5513Hs8880ytOzjj3/RzcnIoKyurtL958+b7jZmfN28e27dvp0ePHuTm5vLaa68xc+ZMANq2bcvnn3++3/t37tzJYYcdRvfu3Vm2bFmomGpTI+jcuTMfffQRENRutm/fTps2+9/UWlRUBEDXrl0xMy644ALeeOON8vcPHTqUpk2bkpeXx7HHHsu6deuA4B6a5s2bh4q5JpElAjPLAe4HhgD5wAgzy69QbAjQLfa4EnggqnhEUqVVq1a0bt26/JvjX//6V/r370/r1q1p2bIlb731FsB+3+ITvf/++/To0YOxY8dSUFDAe++9R8uWLdm5c2fS8oMGDSrvXAQqXeyaN2/OpEmTePTRR9m2bVul8vELUd++fZk1axYQfOuveJy4H//4x0yfPp1du3YBQfPHp59+yscff8x3v/tdfv7zn3PDDTfw9ttvs2vXLrZv386ZZ57JpEmTyj+rpt9VWMccc8x+NYWZM2cybdo0NmzYwIYNG1i/fj3z589n9+7dnH766cyZM6f89/j000/Tq1cvcnJyGDhwIF999RUPPvhg+bGWLFnCK6+8UukzX3311fIkmPj44Q9/WKnsT3/6Ux555BEAnnzySQYOHFgpaXfq1Ini4mK2bNkCwD/+8Q++//3vA0E/wIIFCwD47LPPWLt2LUcddRQQNBsdd9xxoX9X1YmyaehkoMTdPwAws8eBoUBxQpmhwKMefBV5y8wOM7MO7r45wrhE6tXu3bv3a765/vrreeSRR8o7QI866ij+8pe/AMEokl/84he0aNGCAQMG0KpVq0rHmzRpEgsWLCAnJ4f8/HyGDBnCQQcdRJMmTejVqxeXXXZZebMMwC233MJVV13FcccdR05ODuPHjy9vUonr0KEDI0aM4P7772fy5MlcddVV9OzZk7KyMk4//XSmTJnC+PHjGTFiBE888QT9+/enQ4cOtGzZsvyCHzdo0CDeffddTj31VCAYPvu3v/2NkpISfvOb33DQQQeVt3vv3LmToUOHsmfPHtyde++9t9L5VvW7CqNFixZ07dqVkpISOnbsyIsvvsif//zn/fb37duX5557juHDhzNmzBj69u2LmdG+fXumTZsGBM01s2fP5te//jV33303zZo1Izc3t3yUzoEaNWoUF198MUcffTRt2rTZL/n37t2boqIiOnbsyPjx4zn99NNp2rQpRx55JA8//DAQJN358+eTn59PTk4O99xzD23btgWC2t5ZZ51Vp/jKxXus6/sBnA9MS9i+GLivQpm5QN+E7f8BCpIc60pgKbC0S5cufiBum7PKb5uz6oDeK41XcXFxQ4dQKzt37ix/PmHCBL/mmmsaMJr97dmzx/fu3evu7m+88Yb36tWrYQMK6emnn/abb765ocNIuX79+vm2bduS7kv2/wJY6lVcr6OsESRrtKzYCBmmDO4+FZgKUFBQEK6htYLG0pEo2e3vf/87EyZMoKysbL9vfo3Bxo0bueCCC9i3bx8HH3zwfs0kjdmwYcMqjcTJdFu2bOH666/fr0O/LqJMBKXAEQnbnYGKXdxhyohkjOHDhzN8+PCGDiOpbt26sXz58oYO44DEh8Bmi3bt2pUPB64PUY4aWgJ0M7M8MzsYuBCYU6HMHOCS2OihU4Dtrv4BqSUPORpHJBscyP+HyGoE7l5mZmOAF4EcYLq7rzaz0bH9U4DngTOBEmA3cHlU8UhmatasGVu3btVU1CJ8ux5Bs2bNavU+S7dvUwUFBb506dKGDkMaCa1QJrK/qlYoM7Nl7l6Q7D26s1jSWvxGGxE5cJprSEQkyykRiIhkOSUCEZEsl3adxWa2BTjQpZYOBz6rsVRm0TlnB51zdqjLOR/p7u2S7Ui7RFAXZra0ql7zTKVzzg465+wQ1TmraUhEJMspEYiIZLlsSwRTGzqABqBzzg465+wQyTlnVR+BiIhUlm01AhERqUCJQEQky2VkIjCzwWa2xsxKzGxckv1mZpNj+1eY2QkNEWd9CnHOF8XOdYWZvWFmvRoizvpU0zknlDvJzL4xs/NTGV8UwpyzmQ0wsyIzW21mlRfdTTMh/m23MrPnzOyd2Dmn9SzGZjbdzD41s1VV7K//61dVS5el64Ngyuv3gaOAg4F3gPwKZc4EXiBYIe0UYFFDx52Ccz4NaB17PiQbzjmh3P8jmPL8/IaOOwV/58MI1gXvEttu39Bxp+CcbwJ+H3veDtgGHNzQsdfhnE8HTgBWVbG/3q9fmVgjOBkocfcP3P1r4HFgaIUyQ4FHPfAWcJiZdUh1oPWoxnN29zfc/fPY5lsEq8GlszB/Z4CrgaeAT1MZXETCnPNI4Gl33wjg7ul+3mHO2YGWFixIcQhBIihLbZj1x90XEpxDVer9+pWJiaAT8FHCdmnstdqWSSe1PZ9RBN8o0lmN52xmnYBhwJQUxhWlMH/nY4DWZvaymS0zs0tSFl00wpzzfcD3CZa5XQlc6+77UhNeg6j361cmrkeQbJmqimNkw5RJJ6HPx8zOIEgEfSONKHphznkSMNbdv8mQ1cvCnHMT4ETgB0Bz4E0ze8vd10YdXETCnPOPgSJgINAV+IeZveruOyKOraHU+/UrExNBKXBEwnZngm8KtS2TTkKdj5n1BKYBQ9x9a4pii0qYcy4AHo8lgcOBM82szN2fSUmE9S/sv+3P3P1L4EszWwj0AtI1EYQ558uBuz1oQC8xs/XA94DFqQkx5er9+pWJTUNLgG5mlmdmBwMXAnMqlJkDXBLrfT8F2O7um1MdaD2q8ZzNrAvwNHBxGn87TFTjObt7nrvnunsu8CTwqzROAhDu3/azQD8za2Jm3wUKgXdTHGd9CnPOGwlqQJjZvwHHAh+kNMrUqvfrV8bVCNy9zMzGAC8SjDiY7u6rzWx0bP8UghEkZwIlwG6CbxRpK+Q53wq0Bf4U+4Zc5mk8c2PIc84oYc7Z3d81s3nACmAfMM3dkw5DTAch/853Ag+b2UqCZpOx7p6201Ob2UxgAHC4mZUC44GmEN31S1NMiIhkuUxsGhIRkVpQIhARyXJKBCIiWU6JQEQkyykRiIhkOSUCaZRis4UWJTxyqym7qx4+72EzWx/7rLfN7NQDOMY0M8uPPb+pwr436hpj7Djx38uq2Iybh9VQvreZnVkfny2ZS8NHpVEys13ufkh9l63mGA8Dc939STMbBEx09551OF6dY6rpuGb2CLDW3f+zmvKXAQXuPqa+Y5HMoRqBpAUzO8TM/if2bX2lmVWaadTMOpjZwoRvzP1irw8yszdj7/1vM6vpAr0QODr23utjx1plZr+OvdbCzP4em/9+lZkNj73+spkVmNndQPNYHI/F9u2K/Xwi8Rt6rCZynpnlmNk9ZrbEgjnmfxni1/ImscnGzOxkC9aZWB77eWzsTtw7gOGxWIbHYp8e+5zlyX6PkoUaeu5tPfRI9gC+IZhIrAiYTXAX/KGxfYcT3FUZr9Huiv38D+Dm2PMcoGWs7EKgRez1scCtST7vYWLrFQA/AxYRTN62EmhBML3xauB44DzgwYT3tor9fJng23d5TAll4jEOAx6JPT+YYBbJ5sCVwC2x178DLAXyksS5K+H8/hsYHNs+FGgSe/5D4KnY88uA+xLefxfw89jzwwjmIGrR0H9vPRr2kXFTTEjG+Je7945vmFlT4C4zO51g6oROwL8BnyS8ZwkwPVb2GXcvMrP+QD7wemxqjYMJvkknc4+Z3QJsIZih9QfAbA8mcMPMngb6AfOAiWb2e4LmpFdrcV4vAJPN7DvAYGChu/8r1hzV075dRa0V0A1YX+H9zc2sCMgFlgH/SCj/iJl1I5iJsmkVnz8I+KmZ3RDbbgZ0Ib3nI5I6UiKQdHERwepTJ7r7XjPbQHARK+fuC2OJ4izgr2Z2D/A58A93HxHiM37j7k/GN8zsh8kKuftaMzuRYL6XCWY2393vCHMS7r7HzF4mmDp5ODAz/nHA1e7+Yg2H+Je79zazVsBc4CpgMsF8OwvcfVisY/3lKt5vwHnuviZMvJId1Ecg6aIV8GksCZwBHFmxgJkdGSvzIPAQwXJ/bwF9zCze5v9dMzsm5GcuBM6JvacFQbPOq2bWEdjt7n8DJsY+p6K9sZpJMo8TTBTWj2AyNWI//z3+HjM7JvaZSbn7duAa4IbYe1oBm2K7L0soupOgiSzuReBqi1WPzOz4qj5DsocSgaSLx4ACM1tKUDt4L0mZAUCRmS0naMf/o7tvIbgwzjSzFQSJ4XthPtDd3yboO1hM0Gcwzd2XAz2AxbEmmpuB3yV5+1RgRbyzuIL5BOvSvuTB8osQrBNRDLxtwaLlf6aGGnsslncIpmb+vwS1k9cJ+g/iFgD58c5igppD01hsq2LbkuU0fFREJMupRiAikuWUCEREspwSgYhIllMiEBHJckoEIiJZTolARCTLKRGIiGS5/w8uqeiP7P1FvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254  33]\n",
      " [112 201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78       287\n",
      "           1       0.86      0.64      0.73       313\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.78      0.76      0.76       600\n",
      "weighted avg       0.78      0.76      0.76       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_predictions = lr_tuned.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,tuned_predictions))\n",
    "print(classification_report(y_test,tuned_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1323a1d90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(lr_tuned, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Given the accuracy and F1-score of your model, are you satisfied with the results, from a business point of view? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is entirely dependent on the problem we are attempting to solve with this paradigm.\n",
    "- The ratio of accurately anticipated observations to total observations is known as accuracy. Our model has an accuracy of 76%, which is reasonable; nevertheless, we would have to analyse our model using additional performance metrics such as the F1-score.\n",
    "- The F1 score is weighted average of precision and recall (or sensitivity). The precision metric answers the question that from the customers the model labeled as 1, how many actually were correctly labeled as 1. High precision is related to low false positive rates. Our precision is about 86% which is good. \n",
    "- On the other hand, Recall is the ratio of correctly predicted positive obersvations to all the observations in the actual class label=1. As mentioned above, our Recall is 69% which is reasonable, however, not as good as precision. Therefore, Recall is taking a hit on F1 score, which is 78%. \n",
    "- It interpretation can further be explained by confusion matrix below and we can see that False Negative are considerably higher in number as compared to False Positives.\n",
    "[[254  33]\n",
    " [112 201]]\n",
    "- Hence, with the accuracy and the precision of our model, from a business standpoint, we can say that our model is able to predict the polarity of the sentence 76% of the times however, with the 24% wrong predictions, we need to be careful as to what is the actual use case where this model might be used and what impact would the inefficiency of the model will result in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Show five example instances in which your model’s predictions were incorrect. Describe why you think the model was wrong. Don’t just guess: dig deep to figure out the root cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Not even good for camp value!</td>\n",
       "      <td>even good camp value</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The soundtrack wasn't terrible, either.</td>\n",
       "      <td>soundtrack terrible either</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>And, FINALLY, after all that, we get to an ending that would've been great had it been handled by competent people and not Jerry Falwell.</td>\n",
       "      <td>finally get ending would great handled competent people jerry falwell</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Not recommended.</td>\n",
       "      <td>recommended</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>There's barely a boring moment in the film and there are plenty of humorous parts.</td>\n",
       "      <td>barely boring moment film plenty humorous part</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                        Sentence  \\\n",
       "53                                                                                                               Not even good for camp value!     \n",
       "36                                                                                                     The soundtrack wasn't terrible, either.     \n",
       "81   And, FINALLY, after all that, we get to an ending that would've been great had it been handled by competent people and not Jerry Falwell.     \n",
       "172                                                                                                                           Not recommended.     \n",
       "242                                                         There's barely a boring moment in the film and there are plenty of humorous parts.     \n",
       "\n",
       "                                                            clean_sentence  \\\n",
       "53                                                    even good camp value   \n",
       "36                                              soundtrack terrible either   \n",
       "81   finally get ending would great handled competent people jerry falwell   \n",
       "172                                                            recommended   \n",
       "242                         barely boring moment film plenty humorous part   \n",
       "\n",
       "     Polarity  predictions  \n",
       "53          0            1  \n",
       "36          1            0  \n",
       "81          0            1  \n",
       "172         0            1  \n",
       "242         1            0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_test_pred = df_test[['Sentence','clean_sentence','Polarity']]\n",
    "df_test_pred['predictions'] =predictions\n",
    "(df_test_pred[df_test_pred.Polarity != predictions])\n",
    "df_test_pred.loc[[53,36,81,172,242]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Out of the 600 rows in the Test Dataset, there are about 145 number of predictions that are wrongly classified by the Logistic Regression Model.\n",
    "- Looking at the examples, we can see that the model was trained in such a way that it categorized a few words like 'good', 'great', 'recommended' as positive words and positive instances and therefore classfied/Predicted it with a Polarity of 1\n",
    "- Similarly, looking at the other instances, the model categorized the words like 'terrible', 'ending', 'boring' etc as negative words and negative instances and therefore classified/predicted the sentence with a polarity of 0.\n",
    "- Some of the words like 'Not' and 'wasn't' were cleaned using the user-defined method and it led to removal of punctuations and furthermore led to removal of the words because of them being a part of the Stop Words. Hence the meaning of the sentence was completely negated.\n",
    "- Digging down further, we can see that the data cleaning and preprocessing here could have been improved by adding more features like sentiment score, checking the actual polarity of the sentence using TextBlob etc.\n",
    "- We tried removing the words like 'Not' and 'Wasnt' from the stop words and then the incorrect predictions were corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING PYCARET CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pyc = X\n",
    "X_pyc['Polarity'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76dfd_row44_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76dfd_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_76dfd_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_76dfd_row0_col1\" class=\"data row0 col1\" >3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_76dfd_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_76dfd_row1_col1\" class=\"data row1 col1\" >Polarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_76dfd_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "      <td id=\"T_76dfd_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_76dfd_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "      <td id=\"T_76dfd_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_76dfd_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "      <td id=\"T_76dfd_row4_col1\" class=\"data row4 col1\" >(2396, 3500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_76dfd_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "      <td id=\"T_76dfd_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_76dfd_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_76dfd_row6_col1\" class=\"data row6 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_76dfd_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_76dfd_row7_col1\" class=\"data row7 col1\" >3498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_76dfd_row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "      <td id=\"T_76dfd_row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_76dfd_row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "      <td id=\"T_76dfd_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_76dfd_row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "      <td id=\"T_76dfd_row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_76dfd_row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_76dfd_row11_col1\" class=\"data row11 col1\" >(1677, 2521)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_76dfd_row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_76dfd_row12_col1\" class=\"data row12 col1\" >(719, 2521)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_76dfd_row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_76dfd_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_76dfd_row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_76dfd_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_76dfd_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_76dfd_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_76dfd_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_76dfd_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_76dfd_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_76dfd_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_76dfd_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_76dfd_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_76dfd_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_76dfd_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_76dfd_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_76dfd_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_76dfd_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_76dfd_row21_col1\" class=\"data row21 col1\" >1d55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_76dfd_row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "      <td id=\"T_76dfd_row22_col1\" class=\"data row22 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_76dfd_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "      <td id=\"T_76dfd_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_76dfd_row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "      <td id=\"T_76dfd_row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_76dfd_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "      <td id=\"T_76dfd_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_76dfd_row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "      <td id=\"T_76dfd_row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_76dfd_row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "      <td id=\"T_76dfd_row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_76dfd_row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "      <td id=\"T_76dfd_row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_76dfd_row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "      <td id=\"T_76dfd_row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_76dfd_row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "      <td id=\"T_76dfd_row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_76dfd_row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "      <td id=\"T_76dfd_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_76dfd_row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "      <td id=\"T_76dfd_row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_76dfd_row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "      <td id=\"T_76dfd_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_76dfd_row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "      <td id=\"T_76dfd_row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_76dfd_row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "      <td id=\"T_76dfd_row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_76dfd_row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "      <td id=\"T_76dfd_row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_76dfd_row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "      <td id=\"T_76dfd_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_76dfd_row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "      <td id=\"T_76dfd_row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_76dfd_row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "      <td id=\"T_76dfd_row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_76dfd_row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "      <td id=\"T_76dfd_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_76dfd_row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "      <td id=\"T_76dfd_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_76dfd_row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "      <td id=\"T_76dfd_row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_76dfd_row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "      <td id=\"T_76dfd_row43_col1\" class=\"data row43 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_76dfd_row44_col0\" class=\"data row44 col0\" >Remove Perfect Collinearity</td>\n",
       "      <td id=\"T_76dfd_row44_col1\" class=\"data row44 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_76dfd_row45_col0\" class=\"data row45 col0\" >Clustering</td>\n",
       "      <td id=\"T_76dfd_row45_col1\" class=\"data row45 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_76dfd_row46_col0\" class=\"data row46 col0\" >Clustering Iteration</td>\n",
       "      <td id=\"T_76dfd_row46_col1\" class=\"data row46 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_76dfd_row47_col0\" class=\"data row47 col0\" >Polynomial Features</td>\n",
       "      <td id=\"T_76dfd_row47_col1\" class=\"data row47 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_76dfd_row48_col0\" class=\"data row48 col0\" >Polynomial Degree</td>\n",
       "      <td id=\"T_76dfd_row48_col1\" class=\"data row48 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_76dfd_row49_col0\" class=\"data row49 col0\" >Trignometry Features</td>\n",
       "      <td id=\"T_76dfd_row49_col1\" class=\"data row49 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_76dfd_row50_col0\" class=\"data row50 col0\" >Polynomial Threshold</td>\n",
       "      <td id=\"T_76dfd_row50_col1\" class=\"data row50 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_76dfd_row51_col0\" class=\"data row51 col0\" >Group Features</td>\n",
       "      <td id=\"T_76dfd_row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_76dfd_row52_col0\" class=\"data row52 col0\" >Feature Selection</td>\n",
       "      <td id=\"T_76dfd_row52_col1\" class=\"data row52 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_76dfd_row53_col0\" class=\"data row53 col0\" >Feature Selection Method</td>\n",
       "      <td id=\"T_76dfd_row53_col1\" class=\"data row53 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_76dfd_row54_col0\" class=\"data row54 col0\" >Features Selection Threshold</td>\n",
       "      <td id=\"T_76dfd_row54_col1\" class=\"data row54 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_76dfd_row55_col0\" class=\"data row55 col0\" >Feature Interaction</td>\n",
       "      <td id=\"T_76dfd_row55_col1\" class=\"data row55 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_76dfd_row56_col0\" class=\"data row56 col0\" >Feature Ratio</td>\n",
       "      <td id=\"T_76dfd_row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_76dfd_row57_col0\" class=\"data row57 col0\" >Interaction Threshold</td>\n",
       "      <td id=\"T_76dfd_row57_col1\" class=\"data row57 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_76dfd_row58_col0\" class=\"data row58 col0\" >Fix Imbalance</td>\n",
       "      <td id=\"T_76dfd_row58_col1\" class=\"data row58 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76dfd_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_76dfd_row59_col0\" class=\"data row59 col0\" >Fix Imbalance Method</td>\n",
       "      <td id=\"T_76dfd_row59_col1\" class=\"data row59 col1\" >SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16c0e97d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mo = setup(data = X_pyc, target = 'Polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_25654_ th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_25654_row0_col0, #T_25654_row0_col3, #T_25654_row0_col4, #T_25654_row0_col5, #T_25654_row0_col7, #T_25654_row1_col0, #T_25654_row1_col1, #T_25654_row1_col2, #T_25654_row1_col3, #T_25654_row1_col5, #T_25654_row1_col6, #T_25654_row2_col0, #T_25654_row2_col1, #T_25654_row2_col2, #T_25654_row2_col3, #T_25654_row2_col4, #T_25654_row2_col6, #T_25654_row2_col7, #T_25654_row3_col0, #T_25654_row3_col1, #T_25654_row3_col2, #T_25654_row3_col3, #T_25654_row3_col4, #T_25654_row3_col5, #T_25654_row3_col6, #T_25654_row3_col7, #T_25654_row4_col0, #T_25654_row4_col1, #T_25654_row4_col2, #T_25654_row4_col3, #T_25654_row4_col4, #T_25654_row4_col5, #T_25654_row4_col6, #T_25654_row4_col7, #T_25654_row5_col0, #T_25654_row5_col1, #T_25654_row5_col2, #T_25654_row5_col3, #T_25654_row5_col4, #T_25654_row5_col5, #T_25654_row5_col6, #T_25654_row5_col7, #T_25654_row6_col0, #T_25654_row6_col1, #T_25654_row6_col2, #T_25654_row6_col3, #T_25654_row6_col4, #T_25654_row6_col5, #T_25654_row6_col6, #T_25654_row6_col7, #T_25654_row7_col0, #T_25654_row7_col1, #T_25654_row7_col2, #T_25654_row7_col3, #T_25654_row7_col4, #T_25654_row7_col5, #T_25654_row7_col6, #T_25654_row7_col7, #T_25654_row8_col0, #T_25654_row8_col1, #T_25654_row8_col2, #T_25654_row8_col3, #T_25654_row8_col4, #T_25654_row8_col5, #T_25654_row8_col6, #T_25654_row8_col7, #T_25654_row9_col0, #T_25654_row9_col1, #T_25654_row9_col2, #T_25654_row9_col3, #T_25654_row9_col4, #T_25654_row9_col5, #T_25654_row9_col6, #T_25654_row9_col7, #T_25654_row10_col0, #T_25654_row10_col1, #T_25654_row10_col2, #T_25654_row10_col4, #T_25654_row10_col5, #T_25654_row10_col6, #T_25654_row10_col7, #T_25654_row11_col0, #T_25654_row11_col1, #T_25654_row11_col2, #T_25654_row11_col3, #T_25654_row11_col4, #T_25654_row11_col5, #T_25654_row11_col6, #T_25654_row11_col7, #T_25654_row12_col0, #T_25654_row12_col1, #T_25654_row12_col2, #T_25654_row12_col3, #T_25654_row12_col4, #T_25654_row12_col5, #T_25654_row12_col6, #T_25654_row12_col7, #T_25654_row13_col0, #T_25654_row13_col1, #T_25654_row13_col2, #T_25654_row13_col3, #T_25654_row13_col4, #T_25654_row13_col5, #T_25654_row13_col6, #T_25654_row13_col7, #T_25654_row14_col0, #T_25654_row14_col1, #T_25654_row14_col2, #T_25654_row14_col3, #T_25654_row14_col4, #T_25654_row14_col5, #T_25654_row14_col6, #T_25654_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_25654_row0_col1, #T_25654_row0_col2, #T_25654_row0_col6, #T_25654_row1_col4, #T_25654_row1_col7, #T_25654_row2_col5, #T_25654_row10_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_25654_row0_col8, #T_25654_row1_col8, #T_25654_row2_col8, #T_25654_row3_col8, #T_25654_row4_col8, #T_25654_row5_col8, #T_25654_row6_col8, #T_25654_row7_col8, #T_25654_row8_col8, #T_25654_row9_col8, #T_25654_row11_col8, #T_25654_row12_col8, #T_25654_row13_col8, #T_25654_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_25654_row10_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_25654_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_25654_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_25654_row0_col1\" class=\"data row0 col1\" >0.7782</td>\n",
       "      <td id=\"T_25654_row0_col2\" class=\"data row0 col2\" >0.8606</td>\n",
       "      <td id=\"T_25654_row0_col3\" class=\"data row0 col3\" >0.7282</td>\n",
       "      <td id=\"T_25654_row0_col4\" class=\"data row0 col4\" >0.7994</td>\n",
       "      <td id=\"T_25654_row0_col5\" class=\"data row0 col5\" >0.7612</td>\n",
       "      <td id=\"T_25654_row0_col6\" class=\"data row0 col6\" >0.5550</td>\n",
       "      <td id=\"T_25654_row0_col7\" class=\"data row0 col7\" >0.5582</td>\n",
       "      <td id=\"T_25654_row0_col8\" class=\"data row0 col8\" >15.8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row1\" class=\"row_heading level0 row1\" >catboost</th>\n",
       "      <td id=\"T_25654_row1_col0\" class=\"data row1 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_25654_row1_col1\" class=\"data row1 col1\" >0.7770</td>\n",
       "      <td id=\"T_25654_row1_col2\" class=\"data row1 col2\" >0.8586</td>\n",
       "      <td id=\"T_25654_row1_col3\" class=\"data row1 col3\" >0.6425</td>\n",
       "      <td id=\"T_25654_row1_col4\" class=\"data row1 col4\" >0.8650</td>\n",
       "      <td id=\"T_25654_row1_col5\" class=\"data row1 col5\" >0.7355</td>\n",
       "      <td id=\"T_25654_row1_col6\" class=\"data row1 col6\" >0.5507</td>\n",
       "      <td id=\"T_25654_row1_col7\" class=\"data row1 col7\" >0.5701</td>\n",
       "      <td id=\"T_25654_row1_col8\" class=\"data row1 col8\" >36.9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_25654_row2_col0\" class=\"data row2 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_25654_row2_col1\" class=\"data row2 col1\" >0.7728</td>\n",
       "      <td id=\"T_25654_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_25654_row2_col3\" class=\"data row2 col3\" >0.7515</td>\n",
       "      <td id=\"T_25654_row2_col4\" class=\"data row2 col4\" >0.7750</td>\n",
       "      <td id=\"T_25654_row2_col5\" class=\"data row2 col5\" >0.7624</td>\n",
       "      <td id=\"T_25654_row2_col6\" class=\"data row2 col6\" >0.5449</td>\n",
       "      <td id=\"T_25654_row2_col7\" class=\"data row2 col7\" >0.5459</td>\n",
       "      <td id=\"T_25654_row2_col8\" class=\"data row2 col8\" >0.4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n",
       "      <td id=\"T_25654_row3_col0\" class=\"data row3 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_25654_row3_col1\" class=\"data row3 col1\" >0.7716</td>\n",
       "      <td id=\"T_25654_row3_col2\" class=\"data row3 col2\" >0.8315</td>\n",
       "      <td id=\"T_25654_row3_col3\" class=\"data row3 col3\" >0.7209</td>\n",
       "      <td id=\"T_25654_row3_col4\" class=\"data row3 col4\" >0.7926</td>\n",
       "      <td id=\"T_25654_row3_col5\" class=\"data row3 col5\" >0.7543</td>\n",
       "      <td id=\"T_25654_row3_col6\" class=\"data row3 col6\" >0.5418</td>\n",
       "      <td id=\"T_25654_row3_col7\" class=\"data row3 col7\" >0.5447</td>\n",
       "      <td id=\"T_25654_row3_col8\" class=\"data row3 col8\" >1.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row4\" class=\"row_heading level0 row4\" >rf</th>\n",
       "      <td id=\"T_25654_row4_col0\" class=\"data row4 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_25654_row4_col1\" class=\"data row4 col1\" >0.7651</td>\n",
       "      <td id=\"T_25654_row4_col2\" class=\"data row4 col2\" >0.8289</td>\n",
       "      <td id=\"T_25654_row4_col3\" class=\"data row4 col3\" >0.6498</td>\n",
       "      <td id=\"T_25654_row4_col4\" class=\"data row4 col4\" >0.8314</td>\n",
       "      <td id=\"T_25654_row4_col5\" class=\"data row4 col5\" >0.7282</td>\n",
       "      <td id=\"T_25654_row4_col6\" class=\"data row4 col6\" >0.5271</td>\n",
       "      <td id=\"T_25654_row4_col7\" class=\"data row4 col7\" >0.5404</td>\n",
       "      <td id=\"T_25654_row4_col8\" class=\"data row4 col8\" >1.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row5\" class=\"row_heading level0 row5\" >xgboost</th>\n",
       "      <td id=\"T_25654_row5_col0\" class=\"data row5 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_25654_row5_col1\" class=\"data row5 col1\" >0.7615</td>\n",
       "      <td id=\"T_25654_row5_col2\" class=\"data row5 col2\" >0.8302</td>\n",
       "      <td id=\"T_25654_row5_col3\" class=\"data row5 col3\" >0.6596</td>\n",
       "      <td id=\"T_25654_row5_col4\" class=\"data row5 col4\" >0.8155</td>\n",
       "      <td id=\"T_25654_row5_col5\" class=\"data row5 col5\" >0.7279</td>\n",
       "      <td id=\"T_25654_row5_col6\" class=\"data row5 col6\" >0.5202</td>\n",
       "      <td id=\"T_25654_row5_col7\" class=\"data row5 col7\" >0.5305</td>\n",
       "      <td id=\"T_25654_row5_col8\" class=\"data row5 col8\" >13.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row6\" class=\"row_heading level0 row6\" >gbc</th>\n",
       "      <td id=\"T_25654_row6_col0\" class=\"data row6 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_25654_row6_col1\" class=\"data row6 col1\" >0.7567</td>\n",
       "      <td id=\"T_25654_row6_col2\" class=\"data row6 col2\" >0.8295</td>\n",
       "      <td id=\"T_25654_row6_col3\" class=\"data row6 col3\" >0.5972</td>\n",
       "      <td id=\"T_25654_row6_col4\" class=\"data row6 col4\" >0.8614</td>\n",
       "      <td id=\"T_25654_row6_col5\" class=\"data row6 col5\" >0.7030</td>\n",
       "      <td id=\"T_25654_row6_col6\" class=\"data row6 col6\" >0.5092</td>\n",
       "      <td id=\"T_25654_row6_col7\" class=\"data row6 col7\" >0.5351</td>\n",
       "      <td id=\"T_25654_row6_col8\" class=\"data row6 col8\" >2.3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row7\" class=\"row_heading level0 row7\" >ada</th>\n",
       "      <td id=\"T_25654_row7_col0\" class=\"data row7 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_25654_row7_col1\" class=\"data row7 col1\" >0.7537</td>\n",
       "      <td id=\"T_25654_row7_col2\" class=\"data row7 col2\" >0.8017</td>\n",
       "      <td id=\"T_25654_row7_col3\" class=\"data row7 col3\" >0.5936</td>\n",
       "      <td id=\"T_25654_row7_col4\" class=\"data row7 col4\" >0.8570</td>\n",
       "      <td id=\"T_25654_row7_col5\" class=\"data row7 col5\" >0.6994</td>\n",
       "      <td id=\"T_25654_row7_col6\" class=\"data row7 col6\" >0.5032</td>\n",
       "      <td id=\"T_25654_row7_col7\" class=\"data row7 col7\" >0.5286</td>\n",
       "      <td id=\"T_25654_row7_col8\" class=\"data row7 col8\" >0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row8\" class=\"row_heading level0 row8\" >dt</th>\n",
       "      <td id=\"T_25654_row8_col0\" class=\"data row8 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_25654_row8_col1\" class=\"data row8 col1\" >0.7442</td>\n",
       "      <td id=\"T_25654_row8_col2\" class=\"data row8 col2\" >0.7421</td>\n",
       "      <td id=\"T_25654_row8_col3\" class=\"data row8 col3\" >0.7037</td>\n",
       "      <td id=\"T_25654_row8_col4\" class=\"data row8 col4\" >0.7553</td>\n",
       "      <td id=\"T_25654_row8_col5\" class=\"data row8 col5\" >0.7277</td>\n",
       "      <td id=\"T_25654_row8_col6\" class=\"data row8 col6\" >0.4871</td>\n",
       "      <td id=\"T_25654_row8_col7\" class=\"data row8 col7\" >0.4892</td>\n",
       "      <td id=\"T_25654_row8_col8\" class=\"data row8 col8\" >0.4520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row9\" class=\"row_heading level0 row9\" >svm</th>\n",
       "      <td id=\"T_25654_row9_col0\" class=\"data row9 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_25654_row9_col1\" class=\"data row9 col1\" >0.7066</td>\n",
       "      <td id=\"T_25654_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_25654_row9_col3\" class=\"data row9 col3\" >0.8164</td>\n",
       "      <td id=\"T_25654_row9_col4\" class=\"data row9 col4\" >0.7058</td>\n",
       "      <td id=\"T_25654_row9_col5\" class=\"data row9 col5\" >0.7378</td>\n",
       "      <td id=\"T_25654_row9_col6\" class=\"data row9 col6\" >0.4186</td>\n",
       "      <td id=\"T_25654_row9_col7\" class=\"data row9 col7\" >0.4266</td>\n",
       "      <td id=\"T_25654_row9_col8\" class=\"data row9 col8\" >0.5760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row10\" class=\"row_heading level0 row10\" >nb</th>\n",
       "      <td id=\"T_25654_row10_col0\" class=\"data row10 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_25654_row10_col1\" class=\"data row10 col1\" >0.6947</td>\n",
       "      <td id=\"T_25654_row10_col2\" class=\"data row10 col2\" >0.6991</td>\n",
       "      <td id=\"T_25654_row10_col3\" class=\"data row10 col3\" >0.8421</td>\n",
       "      <td id=\"T_25654_row10_col4\" class=\"data row10 col4\" >0.6434</td>\n",
       "      <td id=\"T_25654_row10_col5\" class=\"data row10 col5\" >0.7290</td>\n",
       "      <td id=\"T_25654_row10_col6\" class=\"data row10 col6\" >0.3937</td>\n",
       "      <td id=\"T_25654_row10_col7\" class=\"data row10 col7\" >0.4135</td>\n",
       "      <td id=\"T_25654_row10_col8\" class=\"data row10 col8\" >0.2540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row11\" class=\"row_heading level0 row11\" >lightgbm</th>\n",
       "      <td id=\"T_25654_row11_col0\" class=\"data row11 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_25654_row11_col1\" class=\"data row11 col1\" >0.6673</td>\n",
       "      <td id=\"T_25654_row11_col2\" class=\"data row11 col2\" >0.7208</td>\n",
       "      <td id=\"T_25654_row11_col3\" class=\"data row11 col3\" >0.5044</td>\n",
       "      <td id=\"T_25654_row11_col4\" class=\"data row11 col4\" >0.7290</td>\n",
       "      <td id=\"T_25654_row11_col5\" class=\"data row11 col5\" >0.5945</td>\n",
       "      <td id=\"T_25654_row11_col6\" class=\"data row11 col6\" >0.3289</td>\n",
       "      <td id=\"T_25654_row11_col7\" class=\"data row11 col7\" >0.3455</td>\n",
       "      <td id=\"T_25654_row11_col8\" class=\"data row11 col8\" >3.3630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row12\" class=\"row_heading level0 row12\" >lda</th>\n",
       "      <td id=\"T_25654_row12_col0\" class=\"data row12 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_25654_row12_col1\" class=\"data row12 col1\" >0.6387</td>\n",
       "      <td id=\"T_25654_row12_col2\" class=\"data row12 col2\" >0.6527</td>\n",
       "      <td id=\"T_25654_row12_col3\" class=\"data row12 col3\" >0.6317</td>\n",
       "      <td id=\"T_25654_row12_col4\" class=\"data row12 col4\" >0.6297</td>\n",
       "      <td id=\"T_25654_row12_col5\" class=\"data row12 col5\" >0.6300</td>\n",
       "      <td id=\"T_25654_row12_col6\" class=\"data row12 col6\" >0.2770</td>\n",
       "      <td id=\"T_25654_row12_col7\" class=\"data row12 col7\" >0.2776</td>\n",
       "      <td id=\"T_25654_row12_col8\" class=\"data row12 col8\" >7.4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row13\" class=\"row_heading level0 row13\" >knn</th>\n",
       "      <td id=\"T_25654_row13_col0\" class=\"data row13 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_25654_row13_col1\" class=\"data row13 col1\" >0.6160</td>\n",
       "      <td id=\"T_25654_row13_col2\" class=\"data row13 col2\" >0.6515</td>\n",
       "      <td id=\"T_25654_row13_col3\" class=\"data row13 col3\" >0.5339</td>\n",
       "      <td id=\"T_25654_row13_col4\" class=\"data row13 col4\" >0.6245</td>\n",
       "      <td id=\"T_25654_row13_col5\" class=\"data row13 col5\" >0.5739</td>\n",
       "      <td id=\"T_25654_row13_col6\" class=\"data row13 col6\" >0.2288</td>\n",
       "      <td id=\"T_25654_row13_col7\" class=\"data row13 col7\" >0.2321</td>\n",
       "      <td id=\"T_25654_row13_col8\" class=\"data row13 col8\" >1.0470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25654_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "      <td id=\"T_25654_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_25654_row14_col1\" class=\"data row14 col1\" >0.5480</td>\n",
       "      <td id=\"T_25654_row14_col2\" class=\"data row14 col2\" >0.5545</td>\n",
       "      <td id=\"T_25654_row14_col3\" class=\"data row14 col3\" >0.8079</td>\n",
       "      <td id=\"T_25654_row14_col4\" class=\"data row14 col4\" >0.5242</td>\n",
       "      <td id=\"T_25654_row14_col5\" class=\"data row14 col5\" >0.6344</td>\n",
       "      <td id=\"T_25654_row14_col6\" class=\"data row14 col6\" >0.1076</td>\n",
       "      <td id=\"T_25654_row14_col7\" class=\"data row14 col7\" >0.1279</td>\n",
       "      <td id=\"T_25654_row14_col8\" class=\"data row14 col8\" >2.7930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16c114410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl = compare_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
